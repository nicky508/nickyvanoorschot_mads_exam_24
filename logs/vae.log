2024-06-20 08:37:24.063 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:37:43.457 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:44:05.901 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:44:17.104 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:46:07.218 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:46:07.468 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 08:47:34.474 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:47:34.731 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 08:47:34.732 | INFO     | __main__:main:58 - the shape after: torch.Size([32, 192])
2024-06-20 08:47:51.604 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:47:51.874 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 08:47:51.876 | INFO     | __main__:main:58 - the shape after: torch.Size([32, 192])
2024-06-20 08:51:32.391 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:57:58.835 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:57:59.114 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 08:57:59.116 | INFO     | __main__:main:58 - the shape after: torch.Size([32, 192])
2024-06-20 08:59:51.265 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 08:59:51.519 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 08:59:51.520 | INFO     | __main__:main:58 - the shape after: torch.Size([32, 192])
2024-06-20 09:00:16.757 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:00:17.027 | INFO     | __main__:main:55 - the latent shape : torch.Size([32, 2])
2024-06-20 09:00:17.028 | INFO     | __main__:main:58 - the shape after: torch.Size([32, 192])
2024-06-20 09:00:17.029 | INFO     | __main__:main:62 - Untrained loss: 10.979490280151367
2024-06-20 09:02:02.314 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:02:24.805 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:05:19.343 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:06:34.497 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:06:34.758 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 09:06:34.759 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 09:06:34.760 | INFO     | __main__:main:61 - Untrained loss: 11.196139335632324
2024-06-20 09:06:34.760 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 09:07:07.408 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:07:07.666 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 09:07:07.667 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 09:07:07.668 | INFO     | __main__:main:61 - Untrained loss: 9.934972763061523
2024-06-20 09:07:07.669 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 09:07:50.871 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:07:51.134 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 09:07:51.136 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 09:07:51.137 | INFO     | __main__:main:61 - Untrained loss: 12.114270210266113
2024-06-20 09:07:51.138 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 09:07:51.142 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-090751
2024-06-20 09:07:51.794 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 09:08:36.481 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:08:36.733 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 09:08:36.734 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 09:08:36.734 | INFO     | __main__:main:61 - Untrained loss: 14.624861717224121
2024-06-20 09:08:36.735 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 09:08:36.738 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-090836
2024-06-20 09:08:37.408 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 09:10:44.006 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 09:10:44.287 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 09:10:44.289 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:07:24.050 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:07:24.310 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:07:24.311 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:08:25.887 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:08:26.145 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:08:26.146 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:08:46.667 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:08:46.920 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:08:46.921 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:10:49.448 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:10:49.716 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:10:49.717 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:10:49.719 | INFO     | __main__:main:61 - Untrained loss: 11.545476913452148
2024-06-20 11:10:49.720 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:10:49.723 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-111049
2024-06-20 11:10:50.338 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:12:10.587 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:12:10.841 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:12:10.842 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:12:10.843 | INFO     | __main__:main:61 - Untrained loss: 11.881972312927246
2024-06-20 11:12:10.844 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:12:10.847 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-111210
2024-06-20 11:12:11.434 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:13:17.774 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:13:18.039 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-20 11:13:18.040 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:13:18.041 | INFO     | __main__:main:61 - Untrained loss: 12.805505752563477
2024-06-20 11:13:18.042 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:13:18.044 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-111318
2024-06-20 11:13:18.659 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:13:19.941 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 3.1638 test 2.3894 metric ['2.3894']
2024-06-20 11:13:21.307 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 2.3496 test 2.3209 metric ['2.3209']
2024-06-20 11:13:22.566 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 2.2874 test 2.0562 metric ['2.0562']
2024-06-20 11:13:23.849 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 1.9264 test 1.8279 metric ['1.8279']
2024-06-20 11:13:25.313 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 1.7779 test 1.7475 metric ['1.7475']
2024-06-20 11:13:26.524 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 1.7232 test 1.7045 metric ['1.7045']
2024-06-20 11:13:27.965 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 1.6816 test 1.6716 metric ['1.6716']
2024-06-20 11:13:29.536 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 1.6418 test 1.6393 metric ['1.6393']
2024-06-20 11:13:31.384 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 1.6090 test 1.6160 metric ['1.6160']
2024-06-20 11:13:33.380 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 1.5772 test 1.5998 metric ['1.5998']
2024-06-20 11:13:35.364 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 1.5535 test 1.5694 metric ['1.5694']
2024-06-20 11:13:37.593 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 1.5128 test 1.5258 metric ['1.5258']
2024-06-20 11:13:39.754 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 1.4800 test 1.4924 metric ['1.4924']
2024-06-20 11:13:41.898 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 1.4541 test 1.4810 metric ['1.4810']
2024-06-20 11:13:44.237 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 1.4300 test 1.4471 metric ['1.4471']
2024-06-20 11:13:46.528 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 1.3961 test 1.4205 metric ['1.4205']
2024-06-20 11:13:49.032 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 1.3757 test 1.4286 metric ['1.4286']
2024-06-20 11:13:49.033 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.4205, current loss 1.4286.Counter 1/10.
2024-06-20 11:13:51.305 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 1.3582 test 1.3779 metric ['1.3779']
2024-06-20 11:13:53.500 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 1.3234 test 1.3687 metric ['1.3687']
2024-06-20 11:13:55.931 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 1.3076 test 1.3887 metric ['1.3887']
2024-06-20 11:13:55.932 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.3687, current loss 1.3887.Counter 1/10.
2024-06-20 11:13:58.916 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 1.2852 test 1.3618 metric ['1.3618']
2024-06-20 11:14:01.611 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 1.2714 test 1.3064 metric ['1.3064']
2024-06-20 11:14:03.939 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 1.2601 test 1.3131 metric ['1.3131']
2024-06-20 11:14:03.940 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.3064, current loss 1.3131.Counter 1/10.
2024-06-20 11:14:06.332 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 1.2476 test 1.2977 metric ['1.2977']
2024-06-20 11:14:08.557 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 1.2238 test 1.2714 metric ['1.2714']
2024-06-20 11:14:10.772 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 1.2176 test 1.2779 metric ['1.2779']
2024-06-20 11:14:10.772 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2714, current loss 1.2779.Counter 1/10.
2024-06-20 11:14:13.043 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 1.1995 test 1.2469 metric ['1.2469']
2024-06-20 11:14:15.405 | INFO     | mltrainer.trainer:report:191 - Epoch 27 train 1.1848 test 1.2343 metric ['1.2343']
2024-06-20 11:14:17.609 | INFO     | mltrainer.trainer:report:191 - Epoch 28 train 1.1835 test 1.2389 metric ['1.2389']
2024-06-20 11:14:17.610 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2343, current loss 1.2389.Counter 1/10.
2024-06-20 11:14:19.777 | INFO     | mltrainer.trainer:report:191 - Epoch 29 train 1.1594 test 1.2342 metric ['1.2342']
2024-06-20 11:14:22.096 | INFO     | mltrainer.trainer:report:191 - Epoch 30 train 1.1504 test 1.2152 metric ['1.2152']
2024-06-20 11:14:24.337 | INFO     | mltrainer.trainer:report:191 - Epoch 31 train 1.1250 test 1.1991 metric ['1.1991']
2024-06-20 11:14:26.475 | INFO     | mltrainer.trainer:report:191 - Epoch 32 train 1.1237 test 1.2060 metric ['1.2060']
2024-06-20 11:14:26.475 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1991, current loss 1.2060.Counter 1/10.
2024-06-20 11:14:28.611 | INFO     | mltrainer.trainer:report:191 - Epoch 33 train 1.1223 test 1.1721 metric ['1.1721']
2024-06-20 11:14:30.745 | INFO     | mltrainer.trainer:report:191 - Epoch 34 train 1.0985 test 1.1649 metric ['1.1649']
2024-06-20 11:14:32.960 | INFO     | mltrainer.trainer:report:191 - Epoch 35 train 1.0798 test 1.1629 metric ['1.1629']
2024-06-20 11:14:35.078 | INFO     | mltrainer.trainer:report:191 - Epoch 36 train 1.0604 test 1.1405 metric ['1.1405']
2024-06-20 11:14:37.135 | INFO     | mltrainer.trainer:report:191 - Epoch 37 train 1.0612 test 1.1308 metric ['1.1308']
2024-06-20 11:14:39.300 | INFO     | mltrainer.trainer:report:191 - Epoch 38 train 1.0643 test 1.1532 metric ['1.1532']
2024-06-20 11:14:39.301 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1308, current loss 1.1532.Counter 1/10.
2024-06-20 11:14:41.390 | INFO     | mltrainer.trainer:report:191 - Epoch 39 train 1.0509 test 1.1311 metric ['1.1311']
2024-06-20 11:14:41.391 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1308, current loss 1.1311.Counter 2/10.
2024-06-20 11:14:43.646 | INFO     | mltrainer.trainer:report:191 - Epoch 40 train 1.0351 test 1.1052 metric ['1.1052']
2024-06-20 11:14:45.748 | INFO     | mltrainer.trainer:report:191 - Epoch 41 train 1.0301 test 1.1090 metric ['1.1090']
2024-06-20 11:14:45.749 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1052, current loss 1.1090.Counter 1/10.
2024-06-20 11:14:47.990 | INFO     | mltrainer.trainer:report:191 - Epoch 42 train 1.0234 test 1.1000 metric ['1.1000']
2024-06-20 11:14:50.278 | INFO     | mltrainer.trainer:report:191 - Epoch 43 train 1.0061 test 1.0934 metric ['1.0934']
2024-06-20 11:14:52.518 | INFO     | mltrainer.trainer:report:191 - Epoch 44 train 1.0129 test 1.1043 metric ['1.1043']
2024-06-20 11:14:52.518 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0934, current loss 1.1043.Counter 1/10.
2024-06-20 11:14:54.694 | INFO     | mltrainer.trainer:report:191 - Epoch 45 train 0.9859 test 1.0816 metric ['1.0816']
2024-06-20 11:14:56.923 | INFO     | mltrainer.trainer:report:191 - Epoch 46 train 0.9813 test 1.0752 metric ['1.0752']
2024-06-20 11:14:59.232 | INFO     | mltrainer.trainer:report:191 - Epoch 47 train 0.9706 test 1.0681 metric ['1.0681']
2024-06-20 11:15:01.474 | INFO     | mltrainer.trainer:report:191 - Epoch 48 train 0.9713 test 1.0684 metric ['1.0684']
2024-06-20 11:15:01.476 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0681, current loss 1.0684.Counter 1/10.
2024-06-20 11:15:03.716 | INFO     | mltrainer.trainer:report:191 - Epoch 49 train 0.9562 test 1.0605 metric ['1.0605']
2024-06-20 11:15:06.040 | INFO     | mltrainer.trainer:report:191 - Epoch 50 train 0.9521 test 1.0496 metric ['1.0496']
2024-06-20 11:15:08.222 | INFO     | mltrainer.trainer:report:191 - Epoch 51 train 0.9458 test 1.0492 metric ['1.0492']
2024-06-20 11:15:10.403 | INFO     | mltrainer.trainer:report:191 - Epoch 52 train 0.9372 test 1.0432 metric ['1.0432']
2024-06-20 11:15:12.670 | INFO     | mltrainer.trainer:report:191 - Epoch 53 train 0.9319 test 1.0526 metric ['1.0526']
2024-06-20 11:15:12.671 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0432, current loss 1.0526.Counter 1/10.
2024-06-20 11:15:14.961 | INFO     | mltrainer.trainer:report:191 - Epoch 54 train 0.9283 test 1.0646 metric ['1.0646']
2024-06-20 11:15:14.962 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0432, current loss 1.0646.Counter 2/10.
2024-06-20 11:15:17.227 | INFO     | mltrainer.trainer:report:191 - Epoch 55 train 0.9373 test 1.0578 metric ['1.0577']
2024-06-20 11:15:17.228 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0432, current loss 1.0578.Counter 3/10.
2024-06-20 11:15:19.617 | INFO     | mltrainer.trainer:report:191 - Epoch 56 train 0.9125 test 1.0352 metric ['1.0352']
2024-06-20 11:15:21.953 | INFO     | mltrainer.trainer:report:191 - Epoch 57 train 0.9126 test 1.0237 metric ['1.0237']
2024-06-20 11:15:24.402 | INFO     | mltrainer.trainer:report:191 - Epoch 58 train 0.8950 test 1.0212 metric ['1.0212']
2024-06-20 11:15:26.704 | INFO     | mltrainer.trainer:report:191 - Epoch 59 train 0.8958 test 1.0170 metric ['1.0170']
2024-06-20 11:15:29.069 | INFO     | mltrainer.trainer:report:191 - Epoch 60 train 0.9106 test 1.0090 metric ['1.0090']
2024-06-20 11:15:31.371 | INFO     | mltrainer.trainer:report:191 - Epoch 61 train 0.8888 test 1.0128 metric ['1.0128']
2024-06-20 11:15:31.372 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0090, current loss 1.0128.Counter 1/10.
2024-06-20 11:15:33.718 | INFO     | mltrainer.trainer:report:191 - Epoch 62 train 0.8834 test 0.9956 metric ['0.9956']
2024-06-20 11:15:36.226 | INFO     | mltrainer.trainer:report:191 - Epoch 63 train 0.8701 test 1.0257 metric ['1.0257']
2024-06-20 11:15:36.227 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9956, current loss 1.0257.Counter 1/10.
2024-06-20 11:15:38.643 | INFO     | mltrainer.trainer:report:191 - Epoch 64 train 0.8707 test 1.0000 metric ['1.0000']
2024-06-20 11:15:38.645 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9956, current loss 1.0000.Counter 2/10.
2024-06-20 11:15:41.140 | INFO     | mltrainer.trainer:report:191 - Epoch 65 train 0.8578 test 0.9965 metric ['0.9965']
2024-06-20 11:15:41.141 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9956, current loss 0.9965.Counter 3/10.
2024-06-20 11:15:43.740 | INFO     | mltrainer.trainer:report:191 - Epoch 66 train 0.8859 test 1.0176 metric ['1.0176']
2024-06-20 11:15:43.741 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9956, current loss 1.0176.Counter 4/10.
2024-06-20 11:15:46.350 | INFO     | mltrainer.trainer:report:191 - Epoch 67 train 0.8539 test 0.9944 metric ['0.9944']
2024-06-20 11:15:48.926 | INFO     | mltrainer.trainer:report:191 - Epoch 68 train 0.8445 test 0.9763 metric ['0.9763']
2024-06-20 11:15:51.479 | INFO     | mltrainer.trainer:report:191 - Epoch 69 train 0.8415 test 0.9729 metric ['0.9729']
2024-06-20 11:15:54.201 | INFO     | mltrainer.trainer:report:191 - Epoch 70 train 0.8488 test 0.9662 metric ['0.9662']
2024-06-20 11:15:56.754 | INFO     | mltrainer.trainer:report:191 - Epoch 71 train 0.8244 test 0.9548 metric ['0.9548']
2024-06-20 11:15:59.404 | INFO     | mltrainer.trainer:report:191 - Epoch 72 train 0.8366 test 0.9511 metric ['0.9511']
2024-06-20 11:16:02.011 | INFO     | mltrainer.trainer:report:191 - Epoch 73 train 0.8288 test 0.9600 metric ['0.9600']
2024-06-20 11:16:02.011 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9600.Counter 1/10.
2024-06-20 11:16:04.722 | INFO     | mltrainer.trainer:report:191 - Epoch 74 train 0.8316 test 0.9529 metric ['0.9529']
2024-06-20 11:16:04.723 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9529.Counter 2/10.
2024-06-20 11:16:07.466 | INFO     | mltrainer.trainer:report:191 - Epoch 75 train 0.8210 test 0.9658 metric ['0.9658']
2024-06-20 11:16:07.467 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9658.Counter 3/10.
2024-06-20 11:16:10.132 | INFO     | mltrainer.trainer:report:191 - Epoch 76 train 0.8253 test 0.9709 metric ['0.9709']
2024-06-20 11:16:10.132 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9709.Counter 4/10.
2024-06-20 11:16:13.003 | INFO     | mltrainer.trainer:report:191 - Epoch 77 train 0.8108 test 0.9513 metric ['0.9513']
2024-06-20 11:16:13.004 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9513.Counter 5/10.
2024-06-20 11:16:15.847 | INFO     | mltrainer.trainer:report:191 - Epoch 78 train 0.8134 test 0.9729 metric ['0.9729']
2024-06-20 11:16:15.848 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9511, current loss 0.9729.Counter 6/10.
2024-06-20 11:16:18.656 | INFO     | mltrainer.trainer:report:191 - Epoch 79 train 0.8045 test 0.9422 metric ['0.9422']
2024-06-20 11:16:21.375 | INFO     | mltrainer.trainer:report:191 - Epoch 80 train 0.8093 test 0.9303 metric ['0.9303']
2024-06-20 11:16:24.204 | INFO     | mltrainer.trainer:report:191 - Epoch 81 train 0.8024 test 0.9494 metric ['0.9494']
2024-06-20 11:16:24.205 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9303, current loss 0.9494.Counter 1/10.
2024-06-20 11:16:26.922 | INFO     | mltrainer.trainer:report:191 - Epoch 82 train 0.7950 test 0.9813 metric ['0.9813']
2024-06-20 11:16:26.923 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9303, current loss 0.9813.Counter 2/10.
2024-06-20 11:16:29.839 | INFO     | mltrainer.trainer:report:191 - Epoch 83 train 0.7869 test 0.9330 metric ['0.9330']
2024-06-20 11:16:29.840 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9303, current loss 0.9330.Counter 3/10.
2024-06-20 11:16:32.824 | INFO     | mltrainer.trainer:report:191 - Epoch 84 train 0.8089 test 0.9661 metric ['0.9661']
2024-06-20 11:16:32.824 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9303, current loss 0.9661.Counter 4/10.
2024-06-20 11:16:35.793 | INFO     | mltrainer.trainer:report:191 - Epoch 85 train 0.7956 test 0.9219 metric ['0.9219']
2024-06-20 11:16:38.696 | INFO     | mltrainer.trainer:report:191 - Epoch 86 train 0.7951 test 0.9290 metric ['0.9290']
2024-06-20 11:16:38.696 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9219, current loss 0.9290.Counter 1/10.
2024-06-20 11:16:41.639 | INFO     | mltrainer.trainer:report:191 - Epoch 87 train 0.7794 test 0.9322 metric ['0.9322']
2024-06-20 11:16:41.640 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9219, current loss 0.9322.Counter 2/10.
2024-06-20 11:16:44.394 | INFO     | mltrainer.trainer:report:191 - Epoch 88 train 0.7799 test 0.9694 metric ['0.9694']
2024-06-20 11:16:44.395 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9219, current loss 0.9694.Counter 3/10.
2024-06-20 11:16:47.090 | INFO     | mltrainer.trainer:report:191 - Epoch 89 train 0.7799 test 0.9193 metric ['0.9193']
2024-06-20 11:16:49.725 | INFO     | mltrainer.trainer:report:191 - Epoch 90 train 0.7969 test 0.9400 metric ['0.9400']
2024-06-20 11:16:49.726 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9193, current loss 0.9400.Counter 1/10.
2024-06-20 11:16:52.470 | INFO     | mltrainer.trainer:report:191 - Epoch 91 train 0.7735 test 0.9095 metric ['0.9095']
2024-06-20 11:16:55.038 | INFO     | mltrainer.trainer:report:191 - Epoch 92 train 0.7720 test 0.9042 metric ['0.9042']
2024-06-20 11:16:57.542 | INFO     | mltrainer.trainer:report:191 - Epoch 93 train 0.7632 test 0.9269 metric ['0.9269']
2024-06-20 11:16:57.543 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9269.Counter 1/10.
2024-06-20 11:17:00.117 | INFO     | mltrainer.trainer:report:191 - Epoch 94 train 0.7707 test 0.9234 metric ['0.9234']
2024-06-20 11:17:00.117 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9234.Counter 2/10.
2024-06-20 11:17:02.613 | INFO     | mltrainer.trainer:report:191 - Epoch 95 train 0.7877 test 0.9121 metric ['0.9121']
2024-06-20 11:17:02.614 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9121.Counter 3/10.
2024-06-20 11:17:05.224 | INFO     | mltrainer.trainer:report:191 - Epoch 96 train 0.7649 test 0.9193 metric ['0.9193']
2024-06-20 11:17:05.225 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9193.Counter 4/10.
2024-06-20 11:17:07.685 | INFO     | mltrainer.trainer:report:191 - Epoch 97 train 0.7652 test 0.9308 metric ['0.9308']
2024-06-20 11:17:07.686 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9308.Counter 5/10.
2024-06-20 11:17:10.067 | INFO     | mltrainer.trainer:report:191 - Epoch 98 train 0.7577 test 0.9339 metric ['0.9339']
2024-06-20 11:17:10.068 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9339.Counter 6/10.
2024-06-20 11:17:12.290 | INFO     | mltrainer.trainer:report:191 - Epoch 99 train 0.7670 test 0.9049 metric ['0.9049']
2024-06-20 11:17:12.291 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9042, current loss 0.9049.Counter 7/10.
2024-06-20 11:17:12.299 | SUCCESS  | __main__:main:95 - finished autoencode.py
2024-06-20 11:20:11.173 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:20:11.428 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1])
2024-06-20 11:20:11.429 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:20:11.430 | INFO     | __main__:main:61 - Untrained loss: 8.495073318481445
2024-06-20 11:20:11.431 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:20:11.434 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-112011
2024-06-20 11:20:12.025 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:20:13.431 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 3.2930 test 2.3865 metric ['2.3865']
2024-06-20 11:20:14.701 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 2.3464 test 2.3274 metric ['2.3274']
2024-06-20 11:20:16.065 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 2.3114 test 2.3039 metric ['2.3039']
2024-06-20 11:20:17.386 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 2.2823 test 2.2732 metric ['2.2732']
2024-06-20 11:20:18.640 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 2.2542 test 2.2355 metric ['2.2355']
2024-06-20 11:20:20.020 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 2.2224 test 2.1927 metric ['2.1927']
2024-06-20 11:20:21.468 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 2.1602 test 2.2538 metric ['2.2538']
2024-06-20 11:20:21.469 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1927, current loss 2.2538.Counter 1/10.
2024-06-20 11:20:23.095 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 2.1184 test 2.0818 metric ['2.0818']
2024-06-20 11:20:25.154 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 2.1112 test 2.1028 metric ['2.1028']
2024-06-20 11:20:25.154 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0818, current loss 2.1028.Counter 1/10.
2024-06-20 11:20:27.341 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 2.0763 test 2.0843 metric ['2.0843']
2024-06-20 11:20:27.342 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0818, current loss 2.0843.Counter 2/10.
2024-06-20 11:20:29.492 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 2.0455 test 2.0571 metric ['2.0571']
2024-06-20 11:20:31.847 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 2.0836 test 2.0450 metric ['2.0450']
2024-06-20 11:20:34.123 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 2.0456 test 2.0643 metric ['2.0643']
2024-06-20 11:20:34.123 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0450, current loss 2.0643.Counter 1/10.
2024-06-20 11:20:36.512 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 2.0313 test 2.0200 metric ['2.0200']
2024-06-20 11:20:38.937 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 2.0097 test 2.0090 metric ['2.0090']
2024-06-20 11:20:41.450 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 2.0799 test 2.1346 metric ['2.1346']
2024-06-20 11:20:41.450 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.1346.Counter 1/10.
2024-06-20 11:20:43.911 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 2.1512 test 2.1555 metric ['2.1555']
2024-06-20 11:20:43.912 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.1555.Counter 2/10.
2024-06-20 11:20:46.444 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 2.0622 test 2.0192 metric ['2.0192']
2024-06-20 11:20:46.445 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.0192.Counter 3/10.
2024-06-20 11:20:48.869 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 2.0312 test 2.1181 metric ['2.1181']
2024-06-20 11:20:48.870 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.1181.Counter 4/10.
2024-06-20 11:20:51.295 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 2.0632 test 2.0426 metric ['2.0426']
2024-06-20 11:20:51.296 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.0426.Counter 5/10.
2024-06-20 11:20:53.907 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 1.9963 test 2.0467 metric ['2.0467']
2024-06-20 11:20:53.908 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.0467.Counter 6/10.
2024-06-20 11:20:56.498 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 1.9889 test 2.0149 metric ['2.0149']
2024-06-20 11:20:56.499 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.0149.Counter 7/10.
2024-06-20 11:20:59.223 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 1.9911 test 2.0684 metric ['2.0684']
2024-06-20 11:20:59.224 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.0090, current loss 2.0684.Counter 8/10.
2024-06-20 11:21:01.744 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 1.9732 test 1.9486 metric ['1.9486']
2024-06-20 11:21:04.340 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 2.0113 test 1.9979 metric ['1.9979']
2024-06-20 11:21:04.341 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9979.Counter 1/10.
2024-06-20 11:21:06.877 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 1.9851 test 1.9684 metric ['1.9684']
2024-06-20 11:21:06.878 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9684.Counter 2/10.
2024-06-20 11:21:09.410 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 1.9721 test 2.0304 metric ['2.0304']
2024-06-20 11:21:09.411 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 2.0304.Counter 3/10.
2024-06-20 11:21:12.079 | INFO     | mltrainer.trainer:report:191 - Epoch 27 train 1.9793 test 1.9703 metric ['1.9703']
2024-06-20 11:21:12.080 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9703.Counter 4/10.
2024-06-20 11:21:14.662 | INFO     | mltrainer.trainer:report:191 - Epoch 28 train 1.9972 test 2.1290 metric ['2.1290']
2024-06-20 11:21:14.663 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 2.1290.Counter 5/10.
2024-06-20 11:21:17.687 | INFO     | mltrainer.trainer:report:191 - Epoch 29 train 2.0158 test 1.9893 metric ['1.9893']
2024-06-20 11:21:17.688 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9893.Counter 6/10.
2024-06-20 11:21:20.874 | INFO     | mltrainer.trainer:report:191 - Epoch 30 train 1.9504 test 2.0475 metric ['2.0475']
2024-06-20 11:21:20.875 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 2.0475.Counter 7/10.
2024-06-20 11:21:24.205 | INFO     | mltrainer.trainer:report:191 - Epoch 31 train 1.9966 test 1.9534 metric ['1.9534']
2024-06-20 11:21:24.206 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9534.Counter 8/10.
2024-06-20 11:21:27.362 | INFO     | mltrainer.trainer:report:191 - Epoch 32 train 1.9530 test 1.9555 metric ['1.9555']
2024-06-20 11:21:27.362 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9486, current loss 1.9555.Counter 9/10.
2024-06-20 11:21:29.888 | INFO     | mltrainer.trainer:report:191 - Epoch 33 train 1.9349 test 1.9376 metric ['1.9376']
2024-06-20 11:21:32.382 | INFO     | mltrainer.trainer:report:191 - Epoch 34 train 1.8963 test 1.9391 metric ['1.9391']
2024-06-20 11:21:32.383 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9376, current loss 1.9391.Counter 1/10.
2024-06-20 11:21:34.869 | INFO     | mltrainer.trainer:report:191 - Epoch 35 train 1.9094 test 1.9665 metric ['1.9665']
2024-06-20 11:21:34.870 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.9376, current loss 1.9665.Counter 2/10.
2024-06-20 11:21:37.351 | INFO     | mltrainer.trainer:report:191 - Epoch 36 train 1.8681 test 1.8872 metric ['1.8872']
2024-06-20 11:21:39.808 | INFO     | mltrainer.trainer:report:191 - Epoch 37 train 1.8333 test 1.8831 metric ['1.8831']
2024-06-20 11:21:42.050 | INFO     | mltrainer.trainer:report:191 - Epoch 38 train 1.8922 test 1.8635 metric ['1.8635']
2024-06-20 11:21:44.375 | INFO     | mltrainer.trainer:report:191 - Epoch 39 train 1.8545 test 1.9532 metric ['1.9532']
2024-06-20 11:21:44.376 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.8635, current loss 1.9532.Counter 1/10.
2024-06-20 11:21:46.655 | INFO     | mltrainer.trainer:report:191 - Epoch 40 train 1.8775 test 1.8929 metric ['1.8929']
2024-06-20 11:21:46.656 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.8635, current loss 1.8929.Counter 2/10.
2024-06-20 11:21:48.952 | INFO     | mltrainer.trainer:report:191 - Epoch 41 train 1.8694 test 1.8435 metric ['1.8435']
2024-06-20 11:21:51.268 | INFO     | mltrainer.trainer:report:191 - Epoch 42 train 1.8245 test 1.8226 metric ['1.8226']
2024-06-20 11:21:53.737 | INFO     | mltrainer.trainer:report:191 - Epoch 43 train 1.8449 test 1.7991 metric ['1.7991']
2024-06-20 11:21:56.144 | INFO     | mltrainer.trainer:report:191 - Epoch 44 train 1.8492 test 1.9517 metric ['1.9517']
2024-06-20 11:21:56.145 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7991, current loss 1.9517.Counter 1/10.
2024-06-20 11:21:58.415 | INFO     | mltrainer.trainer:report:191 - Epoch 45 train 1.8519 test 1.7852 metric ['1.7852']
2024-06-20 11:22:00.855 | INFO     | mltrainer.trainer:report:191 - Epoch 46 train 1.7850 test 1.7873 metric ['1.7873']
2024-06-20 11:22:00.856 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7852, current loss 1.7873.Counter 1/10.
2024-06-20 11:22:03.208 | INFO     | mltrainer.trainer:report:191 - Epoch 47 train 1.7966 test 1.9148 metric ['1.9148']
2024-06-20 11:22:03.208 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7852, current loss 1.9148.Counter 2/10.
2024-06-20 11:22:05.786 | INFO     | mltrainer.trainer:report:191 - Epoch 48 train 1.7978 test 1.7885 metric ['1.7885']
2024-06-20 11:22:05.787 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7852, current loss 1.7885.Counter 3/10.
2024-06-20 11:22:08.240 | INFO     | mltrainer.trainer:report:191 - Epoch 49 train 1.8019 test 1.8560 metric ['1.8560']
2024-06-20 11:22:08.241 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7852, current loss 1.8560.Counter 4/10.
2024-06-20 11:22:10.956 | INFO     | mltrainer.trainer:report:191 - Epoch 50 train 1.7778 test 1.8632 metric ['1.8632']
2024-06-20 11:22:10.957 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7852, current loss 1.8632.Counter 5/10.
2024-06-20 11:22:13.313 | INFO     | mltrainer.trainer:report:191 - Epoch 51 train 1.7686 test 1.7713 metric ['1.7713']
2024-06-20 11:22:15.604 | INFO     | mltrainer.trainer:report:191 - Epoch 52 train 1.7504 test 1.7833 metric ['1.7833']
2024-06-20 11:22:15.605 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7713, current loss 1.7833.Counter 1/10.
2024-06-20 11:22:17.932 | INFO     | mltrainer.trainer:report:191 - Epoch 53 train 1.7624 test 1.8049 metric ['1.8049']
2024-06-20 11:22:17.933 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7713, current loss 1.8049.Counter 2/10.
2024-06-20 11:22:20.281 | INFO     | mltrainer.trainer:report:191 - Epoch 54 train 1.8339 test 1.8737 metric ['1.8737']
2024-06-20 11:22:20.282 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7713, current loss 1.8737.Counter 3/10.
2024-06-20 11:22:22.703 | INFO     | mltrainer.trainer:report:191 - Epoch 55 train 1.7972 test 1.8866 metric ['1.8866']
2024-06-20 11:22:22.704 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7713, current loss 1.8866.Counter 4/10.
2024-06-20 11:22:24.993 | INFO     | mltrainer.trainer:report:191 - Epoch 56 train 1.7480 test 1.7491 metric ['1.7491']
2024-06-20 11:22:27.473 | INFO     | mltrainer.trainer:report:191 - Epoch 57 train 1.7074 test 1.7347 metric ['1.7347']
2024-06-20 11:22:29.582 | INFO     | mltrainer.trainer:report:191 - Epoch 58 train 1.7085 test 1.7272 metric ['1.7272']
2024-06-20 11:22:31.785 | INFO     | mltrainer.trainer:report:191 - Epoch 59 train 1.6902 test 1.7353 metric ['1.7353']
2024-06-20 11:22:31.786 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7272, current loss 1.7353.Counter 1/10.
2024-06-20 11:22:33.977 | INFO     | mltrainer.trainer:report:191 - Epoch 60 train 1.7181 test 1.7289 metric ['1.7289']
2024-06-20 11:22:33.977 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7272, current loss 1.7289.Counter 2/10.
2024-06-20 11:22:36.243 | INFO     | mltrainer.trainer:report:191 - Epoch 61 train 1.6972 test 1.7307 metric ['1.7307']
2024-06-20 11:22:36.244 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.7272, current loss 1.7307.Counter 3/10.
2024-06-20 11:22:38.539 | INFO     | mltrainer.trainer:report:191 - Epoch 62 train 1.6855 test 1.7181 metric ['1.7181']
2024-06-20 11:22:40.773 | INFO     | mltrainer.trainer:report:191 - Epoch 63 train 1.6533 test 1.6794 metric ['1.6794']
2024-06-20 11:22:43.159 | INFO     | mltrainer.trainer:report:191 - Epoch 64 train 1.6479 test 1.6512 metric ['1.6512']
2024-06-20 11:22:45.454 | INFO     | mltrainer.trainer:report:191 - Epoch 65 train 1.6260 test 1.6714 metric ['1.6714']
2024-06-20 11:22:45.455 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6512, current loss 1.6714.Counter 1/10.
2024-06-20 11:22:47.850 | INFO     | mltrainer.trainer:report:191 - Epoch 66 train 1.6494 test 1.6330 metric ['1.6330']
2024-06-20 11:22:50.292 | INFO     | mltrainer.trainer:report:191 - Epoch 67 train 1.6893 test 1.8565 metric ['1.8565']
2024-06-20 11:22:50.293 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6330, current loss 1.8565.Counter 1/10.
2024-06-20 11:22:52.791 | INFO     | mltrainer.trainer:report:191 - Epoch 68 train 1.7326 test 1.6790 metric ['1.6790']
2024-06-20 11:22:52.792 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6330, current loss 1.6790.Counter 2/10.
2024-06-20 11:22:55.302 | INFO     | mltrainer.trainer:report:191 - Epoch 69 train 1.6198 test 1.6258 metric ['1.6258']
2024-06-20 11:22:57.746 | INFO     | mltrainer.trainer:report:191 - Epoch 70 train 1.7119 test 1.7324 metric ['1.7324']
2024-06-20 11:22:57.746 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6258, current loss 1.7324.Counter 1/10.
2024-06-20 11:23:00.270 | INFO     | mltrainer.trainer:report:191 - Epoch 71 train 1.6494 test 1.6043 metric ['1.6043']
2024-06-20 11:23:02.756 | INFO     | mltrainer.trainer:report:191 - Epoch 72 train 1.6091 test 1.6221 metric ['1.6221']
2024-06-20 11:23:02.757 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6221.Counter 1/10.
2024-06-20 11:23:05.208 | INFO     | mltrainer.trainer:report:191 - Epoch 73 train 1.6495 test 1.8895 metric ['1.8895']
2024-06-20 11:23:05.209 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.8895.Counter 2/10.
2024-06-20 11:23:07.798 | INFO     | mltrainer.trainer:report:191 - Epoch 74 train 1.7038 test 1.6555 metric ['1.6555']
2024-06-20 11:23:07.799 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6555.Counter 3/10.
2024-06-20 11:23:10.374 | INFO     | mltrainer.trainer:report:191 - Epoch 75 train 1.6332 test 1.6407 metric ['1.6407']
2024-06-20 11:23:10.375 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6407.Counter 4/10.
2024-06-20 11:23:13.087 | INFO     | mltrainer.trainer:report:191 - Epoch 76 train 1.6052 test 1.6157 metric ['1.6157']
2024-06-20 11:23:13.087 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6157.Counter 5/10.
2024-06-20 11:23:15.780 | INFO     | mltrainer.trainer:report:191 - Epoch 77 train 1.6078 test 1.6395 metric ['1.6395']
2024-06-20 11:23:15.782 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6395.Counter 6/10.
2024-06-20 11:23:18.568 | INFO     | mltrainer.trainer:report:191 - Epoch 78 train 1.5789 test 1.6597 metric ['1.6597']
2024-06-20 11:23:18.569 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6597.Counter 7/10.
2024-06-20 11:23:21.341 | INFO     | mltrainer.trainer:report:191 - Epoch 79 train 1.7337 test 1.7180 metric ['1.7180']
2024-06-20 11:23:21.342 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.7180.Counter 8/10.
2024-06-20 11:23:24.215 | INFO     | mltrainer.trainer:report:191 - Epoch 80 train 1.6567 test 1.6471 metric ['1.6471']
2024-06-20 11:23:24.216 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.6043, current loss 1.6471.Counter 9/10.
2024-06-20 11:23:27.051 | INFO     | mltrainer.trainer:report:191 - Epoch 81 train 1.5763 test 1.5690 metric ['1.5690']
2024-06-20 11:23:29.970 | INFO     | mltrainer.trainer:report:191 - Epoch 82 train 1.5874 test 1.5591 metric ['1.5591']
2024-06-20 11:23:32.732 | INFO     | mltrainer.trainer:report:191 - Epoch 83 train 1.5545 test 1.5835 metric ['1.5835']
2024-06-20 11:23:32.733 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5591, current loss 1.5835.Counter 1/10.
2024-06-20 11:23:35.542 | INFO     | mltrainer.trainer:report:191 - Epoch 84 train 1.5945 test 1.5479 metric ['1.5479']
2024-06-20 11:23:38.260 | INFO     | mltrainer.trainer:report:191 - Epoch 85 train 1.5634 test 1.6783 metric ['1.6783']
2024-06-20 11:23:38.261 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5479, current loss 1.6783.Counter 1/10.
2024-06-20 11:23:41.027 | INFO     | mltrainer.trainer:report:191 - Epoch 86 train 1.5563 test 1.5443 metric ['1.5443']
2024-06-20 11:23:43.697 | INFO     | mltrainer.trainer:report:191 - Epoch 87 train 1.5648 test 1.5576 metric ['1.5576']
2024-06-20 11:23:43.698 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5576.Counter 1/10.
2024-06-20 11:23:46.481 | INFO     | mltrainer.trainer:report:191 - Epoch 88 train 1.5229 test 1.5450 metric ['1.5450']
2024-06-20 11:23:46.481 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5450.Counter 2/10.
2024-06-20 11:23:49.203 | INFO     | mltrainer.trainer:report:191 - Epoch 89 train 1.6606 test 1.5609 metric ['1.5609']
2024-06-20 11:23:49.204 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5609.Counter 3/10.
2024-06-20 11:23:51.821 | INFO     | mltrainer.trainer:report:191 - Epoch 90 train 1.6536 test 1.7077 metric ['1.7077']
2024-06-20 11:23:51.822 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.7077.Counter 4/10.
2024-06-20 11:23:54.524 | INFO     | mltrainer.trainer:report:191 - Epoch 91 train 1.6044 test 1.5833 metric ['1.5833']
2024-06-20 11:23:54.525 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5833.Counter 5/10.
2024-06-20 11:23:57.633 | INFO     | mltrainer.trainer:report:191 - Epoch 92 train 1.5201 test 1.5757 metric ['1.5757']
2024-06-20 11:23:57.634 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5757.Counter 6/10.
2024-06-20 11:24:00.135 | INFO     | mltrainer.trainer:report:191 - Epoch 93 train 1.5389 test 1.5630 metric ['1.5630']
2024-06-20 11:24:00.136 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5630.Counter 7/10.
2024-06-20 11:24:02.657 | INFO     | mltrainer.trainer:report:191 - Epoch 94 train 1.5370 test 1.5643 metric ['1.5643']
2024-06-20 11:24:02.658 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5643.Counter 8/10.
2024-06-20 11:24:05.266 | INFO     | mltrainer.trainer:report:191 - Epoch 95 train 1.5077 test 1.5544 metric ['1.5544']
2024-06-20 11:24:05.266 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5443, current loss 1.5544.Counter 9/10.
2024-06-20 11:24:07.744 | INFO     | mltrainer.trainer:report:191 - Epoch 96 train 1.4919 test 1.5232 metric ['1.5232']
2024-06-20 11:24:10.323 | INFO     | mltrainer.trainer:report:191 - Epoch 97 train 1.4987 test 1.5363 metric ['1.5363']
2024-06-20 11:24:10.324 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5232, current loss 1.5363.Counter 1/10.
2024-06-20 11:24:12.902 | INFO     | mltrainer.trainer:report:191 - Epoch 98 train 1.5413 test 1.7338 metric ['1.7338']
2024-06-20 11:24:12.905 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5232, current loss 1.7338.Counter 2/10.
2024-06-20 11:24:15.536 | INFO     | mltrainer.trainer:report:191 - Epoch 99 train 1.5513 test 1.5902 metric ['1.5902']
2024-06-20 11:24:15.537 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.5232, current loss 1.5902.Counter 3/10.
2024-06-20 11:24:15.548 | SUCCESS  | __main__:main:95 - finished autoencode.py
2024-06-20 11:24:22.534 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:24:22.824 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1])
2024-06-20 11:24:22.825 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:24:22.826 | INFO     | __main__:main:61 - Untrained loss: 12.195842742919922
2024-06-20 11:24:22.826 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:24:22.829 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-112422
2024-06-20 11:24:23.405 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:24:24.789 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 3.0982 test 2.3994 metric ['2.3994']
2024-06-20 11:24:26.206 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 2.3696 test 2.3610 metric ['2.3610']
2024-06-20 11:24:27.704 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 2.3325 test 2.3222 metric ['2.3222']
2024-06-20 11:24:42.266 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 11:24:42.516 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 3])
2024-06-20 11:24:42.517 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192])
2024-06-20 11:24:42.518 | INFO     | __main__:main:61 - Untrained loss: 12.263136863708496
2024-06-20 11:24:42.519 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-20 11:24:42.522 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240620-112442
2024-06-20 11:24:43.163 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-20 11:24:44.456 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 3.5672 test 2.4270 metric ['2.4270']
2024-06-20 11:24:45.867 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 2.3719 test 2.3581 metric ['2.3581']
2024-06-20 11:24:47.100 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 2.3314 test 2.2985 metric ['2.2985']
2024-06-20 11:24:48.441 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 2.1706 test 1.9517 metric ['1.9517']
2024-06-20 11:24:49.792 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 1.8316 test 1.7750 metric ['1.7750']
2024-06-20 11:24:51.090 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 1.7309 test 1.7108 metric ['1.7108']
2024-06-20 11:24:52.490 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 1.6841 test 1.6769 metric ['1.6769']
2024-06-20 11:24:54.053 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 1.6463 test 1.6470 metric ['1.6470']
2024-06-20 11:24:55.777 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 1.6155 test 1.6103 metric ['1.6103']
2024-06-20 11:24:57.691 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 1.5719 test 1.5767 metric ['1.5767']
2024-06-20 11:24:59.666 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 1.5380 test 1.5414 metric ['1.5414']
2024-06-20 11:25:01.702 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 1.4878 test 1.5022 metric ['1.5022']
2024-06-20 11:25:03.932 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 1.4626 test 1.4719 metric ['1.4719']
2024-06-20 11:25:06.045 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 1.4470 test 1.4483 metric ['1.4483']
2024-06-20 11:25:08.287 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 1.4041 test 1.4267 metric ['1.4267']
2024-06-20 11:25:10.522 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 1.3861 test 1.3977 metric ['1.3977']
2024-06-20 11:25:12.745 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 1.3536 test 1.3744 metric ['1.3744']
2024-06-20 11:25:15.047 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 1.3338 test 1.3702 metric ['1.3702']
2024-06-20 11:25:17.287 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 1.3015 test 1.3404 metric ['1.3404']
2024-06-20 11:25:19.519 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 1.2960 test 1.3174 metric ['1.3174']
2024-06-20 11:25:21.866 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 1.2698 test 1.3008 metric ['1.3008']
2024-06-20 11:25:24.161 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 1.2418 test 1.2800 metric ['1.2800']
2024-06-20 11:25:26.492 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 1.2193 test 1.2745 metric ['1.2745']
2024-06-20 11:25:28.730 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 1.2087 test 1.2420 metric ['1.2420']
2024-06-20 11:25:31.023 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 1.1938 test 1.2454 metric ['1.2454']
2024-06-20 11:25:31.024 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2420, current loss 1.2454.Counter 1/10.
2024-06-20 11:25:33.318 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 1.1596 test 1.2550 metric ['1.2550']
2024-06-20 11:25:33.319 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2420, current loss 1.2550.Counter 2/10.
2024-06-20 11:25:35.610 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 1.1737 test 1.2002 metric ['1.2002']
2024-06-20 11:25:37.877 | INFO     | mltrainer.trainer:report:191 - Epoch 27 train 1.1330 test 1.2015 metric ['1.2015']
2024-06-20 11:25:37.878 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2002, current loss 1.2015.Counter 1/10.
2024-06-20 11:25:40.250 | INFO     | mltrainer.trainer:report:191 - Epoch 28 train 1.1269 test 1.2097 metric ['1.2097']
2024-06-20 11:25:40.251 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.2002, current loss 1.2097.Counter 2/10.
2024-06-20 11:25:42.390 | INFO     | mltrainer.trainer:report:191 - Epoch 29 train 1.1279 test 1.1840 metric ['1.1840']
2024-06-20 11:25:44.618 | INFO     | mltrainer.trainer:report:191 - Epoch 30 train 1.1010 test 1.1794 metric ['1.1794']
2024-06-20 11:25:46.747 | INFO     | mltrainer.trainer:report:191 - Epoch 31 train 1.1059 test 1.1801 metric ['1.1801']
2024-06-20 11:25:46.748 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1794, current loss 1.1801.Counter 1/10.
2024-06-20 11:25:48.913 | INFO     | mltrainer.trainer:report:191 - Epoch 32 train 1.0903 test 1.1922 metric ['1.1922']
2024-06-20 11:25:48.914 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1794, current loss 1.1922.Counter 2/10.
2024-06-20 11:25:51.180 | INFO     | mltrainer.trainer:report:191 - Epoch 33 train 1.0797 test 1.1983 metric ['1.1983']
2024-06-20 11:25:51.181 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1794, current loss 1.1983.Counter 3/10.
2024-06-20 11:25:53.406 | INFO     | mltrainer.trainer:report:191 - Epoch 34 train 1.0771 test 1.1398 metric ['1.1398']
2024-06-20 11:25:55.687 | INFO     | mltrainer.trainer:report:191 - Epoch 35 train 1.0492 test 1.1526 metric ['1.1526']
2024-06-20 11:25:55.688 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1398, current loss 1.1526.Counter 1/10.
2024-06-20 11:25:57.933 | INFO     | mltrainer.trainer:report:191 - Epoch 36 train 1.0513 test 1.1327 metric ['1.1327']
2024-06-20 11:26:00.130 | INFO     | mltrainer.trainer:report:191 - Epoch 37 train 1.0533 test 1.1304 metric ['1.1304']
2024-06-20 11:26:02.264 | INFO     | mltrainer.trainer:report:191 - Epoch 38 train 1.0330 test 1.1183 metric ['1.1183']
2024-06-20 11:26:04.487 | INFO     | mltrainer.trainer:report:191 - Epoch 39 train 1.0295 test 1.1923 metric ['1.1923']
2024-06-20 11:26:04.488 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1183, current loss 1.1923.Counter 1/10.
2024-06-20 11:26:06.635 | INFO     | mltrainer.trainer:report:191 - Epoch 40 train 1.0172 test 1.1613 metric ['1.1613']
2024-06-20 11:26:06.636 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.1183, current loss 1.1613.Counter 2/10.
2024-06-20 11:26:08.741 | INFO     | mltrainer.trainer:report:191 - Epoch 41 train 1.0224 test 1.1084 metric ['1.1084']
2024-06-20 11:26:10.971 | INFO     | mltrainer.trainer:report:191 - Epoch 42 train 1.0101 test 1.0878 metric ['1.0878']
2024-06-20 11:26:13.159 | INFO     | mltrainer.trainer:report:191 - Epoch 43 train 1.0046 test 1.1043 metric ['1.1043']
2024-06-20 11:26:13.160 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0878, current loss 1.1043.Counter 1/10.
2024-06-20 11:26:15.416 | INFO     | mltrainer.trainer:report:191 - Epoch 44 train 1.0048 test 1.0887 metric ['1.0887']
2024-06-20 11:26:15.416 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0878, current loss 1.0887.Counter 2/10.
2024-06-20 11:26:17.566 | INFO     | mltrainer.trainer:report:191 - Epoch 45 train 0.9991 test 1.0915 metric ['1.0915']
2024-06-20 11:26:17.567 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0878, current loss 1.0915.Counter 3/10.
2024-06-20 11:26:19.721 | INFO     | mltrainer.trainer:report:191 - Epoch 46 train 0.9740 test 1.0817 metric ['1.0817']
2024-06-20 11:26:22.020 | INFO     | mltrainer.trainer:report:191 - Epoch 47 train 0.9871 test 1.0785 metric ['1.0785']
2024-06-20 11:26:24.239 | INFO     | mltrainer.trainer:report:191 - Epoch 48 train 0.9784 test 1.1086 metric ['1.1086']
2024-06-20 11:26:24.240 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0785, current loss 1.1086.Counter 1/10.
2024-06-20 11:26:26.529 | INFO     | mltrainer.trainer:report:191 - Epoch 49 train 0.9710 test 1.0997 metric ['1.0997']
2024-06-20 11:26:26.530 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0785, current loss 1.0997.Counter 2/10.
2024-06-20 11:26:28.773 | INFO     | mltrainer.trainer:report:191 - Epoch 50 train 0.9573 test 1.0585 metric ['1.0585']
2024-06-20 11:26:31.164 | INFO     | mltrainer.trainer:report:191 - Epoch 51 train 0.9552 test 1.0887 metric ['1.0887']
2024-06-20 11:26:31.165 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0585, current loss 1.0887.Counter 1/10.
2024-06-20 11:26:33.479 | INFO     | mltrainer.trainer:report:191 - Epoch 52 train 0.9598 test 1.0591 metric ['1.0591']
2024-06-20 11:26:33.480 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0585, current loss 1.0591.Counter 2/10.
2024-06-20 11:26:35.908 | INFO     | mltrainer.trainer:report:191 - Epoch 53 train 0.9461 test 1.0726 metric ['1.0726']
2024-06-20 11:26:35.908 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0585, current loss 1.0726.Counter 3/10.
2024-06-20 11:26:38.201 | INFO     | mltrainer.trainer:report:191 - Epoch 54 train 0.9633 test 1.0567 metric ['1.0567']
2024-06-20 11:26:40.574 | INFO     | mltrainer.trainer:report:191 - Epoch 55 train 0.9346 test 1.0538 metric ['1.0538']
2024-06-20 11:26:43.032 | INFO     | mltrainer.trainer:report:191 - Epoch 56 train 0.9459 test 1.0499 metric ['1.0499']
2024-06-20 11:26:45.373 | INFO     | mltrainer.trainer:report:191 - Epoch 57 train 0.9281 test 1.0359 metric ['1.0359']
2024-06-20 11:26:47.828 | INFO     | mltrainer.trainer:report:191 - Epoch 58 train 0.9275 test 1.0413 metric ['1.0413']
2024-06-20 11:26:47.829 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0359, current loss 1.0413.Counter 1/10.
2024-06-20 11:26:50.298 | INFO     | mltrainer.trainer:report:191 - Epoch 59 train 0.9302 test 1.0374 metric ['1.0374']
2024-06-20 11:26:50.299 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0359, current loss 1.0374.Counter 2/10.
2024-06-20 11:26:52.841 | INFO     | mltrainer.trainer:report:191 - Epoch 60 train 0.9123 test 1.0402 metric ['1.0402']
2024-06-20 11:26:52.842 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0359, current loss 1.0402.Counter 3/10.
2024-06-20 11:26:55.413 | INFO     | mltrainer.trainer:report:191 - Epoch 61 train 0.9307 test 1.0683 metric ['1.0683']
2024-06-20 11:26:55.414 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0359, current loss 1.0683.Counter 4/10.
2024-06-20 11:26:57.844 | INFO     | mltrainer.trainer:report:191 - Epoch 62 train 0.9051 test 1.0302 metric ['1.0302']
2024-06-20 11:27:00.227 | INFO     | mltrainer.trainer:report:191 - Epoch 63 train 0.9021 test 1.0384 metric ['1.0384']
2024-06-20 11:27:00.228 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0302, current loss 1.0384.Counter 1/10.
2024-06-20 11:27:02.774 | INFO     | mltrainer.trainer:report:191 - Epoch 64 train 0.8979 test 1.0243 metric ['1.0243']
2024-06-20 11:27:05.189 | INFO     | mltrainer.trainer:report:191 - Epoch 65 train 0.8930 test 1.0143 metric ['1.0143']
2024-06-20 11:27:07.750 | INFO     | mltrainer.trainer:report:191 - Epoch 66 train 0.8921 test 1.0175 metric ['1.0175']
2024-06-20 11:27:07.751 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0143, current loss 1.0175.Counter 1/10.
2024-06-20 11:27:10.226 | INFO     | mltrainer.trainer:report:191 - Epoch 67 train 0.9013 test 1.1034 metric ['1.1034']
2024-06-20 11:27:10.227 | INFO     | mltrainer.trainer:__call__:234 - best loss: 1.0143, current loss 1.1034.Counter 2/10.
2024-06-20 11:27:12.818 | INFO     | mltrainer.trainer:report:191 - Epoch 68 train 0.8746 test 1.0051 metric ['1.0051']
2024-06-20 11:27:15.503 | INFO     | mltrainer.trainer:report:191 - Epoch 69 train 0.8838 test 0.9967 metric ['0.9967']
2024-06-20 11:27:17.983 | INFO     | mltrainer.trainer:report:191 - Epoch 70 train 0.8733 test 0.9909 metric ['0.9909']
2024-06-20 11:27:20.509 | INFO     | mltrainer.trainer:report:191 - Epoch 71 train 0.8808 test 1.0450 metric ['1.0450']
2024-06-20 11:27:20.510 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9909, current loss 1.0450.Counter 1/10.
2024-06-20 11:27:22.935 | INFO     | mltrainer.trainer:report:191 - Epoch 72 train 0.8699 test 0.9941 metric ['0.9941']
2024-06-20 11:27:22.936 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9909, current loss 0.9941.Counter 2/10.
2024-06-20 11:27:25.324 | INFO     | mltrainer.trainer:report:191 - Epoch 73 train 0.8675 test 0.9996 metric ['0.9996']
2024-06-20 11:27:25.324 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9909, current loss 0.9996.Counter 3/10.
2024-06-20 11:27:27.820 | INFO     | mltrainer.trainer:report:191 - Epoch 74 train 0.8696 test 0.9867 metric ['0.9867']
2024-06-20 11:27:30.228 | INFO     | mltrainer.trainer:report:191 - Epoch 75 train 0.8701 test 1.0531 metric ['1.0531']
2024-06-20 11:27:30.229 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9867, current loss 1.0531.Counter 1/10.
2024-06-20 11:27:32.770 | INFO     | mltrainer.trainer:report:191 - Epoch 76 train 0.8510 test 0.9800 metric ['0.9800']
2024-06-20 11:27:35.299 | INFO     | mltrainer.trainer:report:191 - Epoch 77 train 0.8521 test 0.9963 metric ['0.9963']
2024-06-20 11:27:35.300 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9800, current loss 0.9963.Counter 1/10.
2024-06-20 11:27:37.984 | INFO     | mltrainer.trainer:report:191 - Epoch 78 train 0.8515 test 0.9737 metric ['0.9737']
2024-06-20 11:27:40.610 | INFO     | mltrainer.trainer:report:191 - Epoch 79 train 0.8588 test 0.9806 metric ['0.9806']
2024-06-20 11:27:40.611 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 0.9806.Counter 1/10.
2024-06-20 11:27:43.194 | INFO     | mltrainer.trainer:report:191 - Epoch 80 train 0.8566 test 0.9951 metric ['0.9951']
2024-06-20 11:27:43.195 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 0.9951.Counter 2/10.
2024-06-20 11:27:45.739 | INFO     | mltrainer.trainer:report:191 - Epoch 81 train 0.8538 test 0.9927 metric ['0.9927']
2024-06-20 11:27:45.739 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 0.9927.Counter 3/10.
2024-06-20 11:27:48.392 | INFO     | mltrainer.trainer:report:191 - Epoch 82 train 0.8340 test 1.0167 metric ['1.0167']
2024-06-20 11:27:48.393 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 1.0167.Counter 4/10.
2024-06-20 11:27:51.265 | INFO     | mltrainer.trainer:report:191 - Epoch 83 train 0.8390 test 1.0019 metric ['1.0019']
2024-06-20 11:27:51.266 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 1.0019.Counter 5/10.
2024-06-20 11:27:54.027 | INFO     | mltrainer.trainer:report:191 - Epoch 84 train 0.8241 test 0.9819 metric ['0.9819']
2024-06-20 11:27:54.028 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 0.9819.Counter 6/10.
2024-06-20 11:27:56.654 | INFO     | mltrainer.trainer:report:191 - Epoch 85 train 0.8396 test 0.9804 metric ['0.9804']
2024-06-20 11:27:56.655 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 0.9804.Counter 7/10.
2024-06-20 11:27:59.351 | INFO     | mltrainer.trainer:report:191 - Epoch 86 train 0.8305 test 1.0058 metric ['1.0058']
2024-06-20 11:27:59.352 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9737, current loss 1.0058.Counter 8/10.
2024-06-20 11:28:02.040 | INFO     | mltrainer.trainer:report:191 - Epoch 87 train 0.8351 test 0.9695 metric ['0.9695']
2024-06-20 11:28:04.700 | INFO     | mltrainer.trainer:report:191 - Epoch 88 train 0.8257 test 0.9849 metric ['0.9849']
2024-06-20 11:28:04.701 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9695, current loss 0.9849.Counter 1/10.
2024-06-20 11:28:07.226 | INFO     | mltrainer.trainer:report:191 - Epoch 89 train 0.8181 test 0.9926 metric ['0.9926']
2024-06-20 11:28:07.228 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9695, current loss 0.9926.Counter 2/10.
2024-06-20 11:28:09.728 | INFO     | mltrainer.trainer:report:191 - Epoch 90 train 0.8289 test 0.9505 metric ['0.9505']
2024-06-20 11:28:12.061 | INFO     | mltrainer.trainer:report:191 - Epoch 91 train 0.8173 test 0.9823 metric ['0.9823']
2024-06-20 11:28:12.062 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9823.Counter 1/10.
2024-06-20 11:28:14.446 | INFO     | mltrainer.trainer:report:191 - Epoch 92 train 0.8067 test 0.9711 metric ['0.9711']
2024-06-20 11:28:14.447 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9711.Counter 2/10.
2024-06-20 11:28:16.891 | INFO     | mltrainer.trainer:report:191 - Epoch 93 train 0.8248 test 0.9911 metric ['0.9911']
2024-06-20 11:28:16.892 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9911.Counter 3/10.
2024-06-20 11:28:22.676 | INFO     | mltrainer.trainer:report:191 - Epoch 94 train 0.8073 test 0.9622 metric ['0.9622']
2024-06-20 11:28:22.677 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9622.Counter 4/10.
2024-06-20 11:28:25.046 | INFO     | mltrainer.trainer:report:191 - Epoch 95 train 0.8053 test 0.9707 metric ['0.9707']
2024-06-20 11:28:25.047 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9707.Counter 5/10.
2024-06-20 11:28:27.440 | INFO     | mltrainer.trainer:report:191 - Epoch 96 train 0.8065 test 0.9615 metric ['0.9615']
2024-06-20 11:28:27.441 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9615.Counter 6/10.
2024-06-20 11:28:29.755 | INFO     | mltrainer.trainer:report:191 - Epoch 97 train 0.8166 test 0.9743 metric ['0.9743']
2024-06-20 11:28:29.755 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9743.Counter 7/10.
2024-06-20 11:28:32.088 | INFO     | mltrainer.trainer:report:191 - Epoch 98 train 0.7944 test 0.9553 metric ['0.9553']
2024-06-20 11:28:32.089 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.9505, current loss 0.9553.Counter 8/10.
2024-06-20 11:28:34.430 | INFO     | mltrainer.trainer:report:191 - Epoch 99 train 0.7952 test 0.9442 metric ['0.9442']
2024-06-20 11:28:34.438 | SUCCESS  | __main__:main:95 - finished autoencode.py
2024-06-20 17:37:06.019 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 17:37:31.786 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 17:37:54.457 | INFO     | __main__:main:24 - starting exam.py
2024-06-20 17:38:39.739 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:07:06.142 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:07:46.597 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:07:46.913 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:09:05.609 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:10:07.219 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:10:31.260 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:10:55.011 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:11:12.047 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:11:12.253 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:11:57.175 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:11:57.374 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:12:34.159 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:12:34.362 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:13:27.289 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:14:10.679 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:14:28.091 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:16:21.577 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:16:48.619 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:16:48.820 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:17:09.802 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:17:10.002 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:17:21.412 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:17:21.615 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 1])
2024-06-21 09:17:48.709 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:18:42.606 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:19:10.255 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:21:36.047 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:22:14.607 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:22:35.082 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:24:13.989 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:24:14.289 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 96])
2024-06-21 09:24:56.378 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:25:13.723 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:25:30.153 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:25:30.359 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 96])
2024-06-21 09:27:25.896 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:27:41.663 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:27:41.876 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 96])
2024-06-21 09:27:56.636 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:27:56.847 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 96])
2024-06-21 09:28:11.177 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:28:11.393 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 48])
2024-06-21 09:28:50.322 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:28:50.539 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:29:10.130 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:29:10.382 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 24])
2024-06-21 09:29:28.267 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:29:28.486 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:31:42.426 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:31:42.651 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:31:51.840 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:31:52.068 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:31:52.120 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 128, 48])
2024-06-21 09:32:03.693 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:32:03.949 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:32:03.958 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 128, 48])
2024-06-21 09:32:40.418 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:32:40.652 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:32:40.669 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 48])
2024-06-21 09:32:40.690 | INFO     | __main__:main:61 - Untrained loss: 202.3251190185547
2024-06-21 09:33:13.949 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:33:14.172 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:33:14.183 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 48])
2024-06-21 09:33:14.184 | INFO     | __main__:main:61 - Untrained loss: 201.2071533203125
2024-06-21 09:33:14.185 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 09:33:14.189 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-093314
2024-06-21 09:33:14.879 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 09:33:25.736 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 145.5989 test 168.9047 metric ['168.9047']
2024-06-21 09:33:59.247 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:33:59.462 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:33:59.473 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 48])
2024-06-21 09:33:59.475 | INFO     | __main__:main:61 - Untrained loss: 200.7129364013672
2024-06-21 09:33:59.475 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 09:33:59.479 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-093359
2024-06-21 09:33:59.946 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 09:34:10.328 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 145.5875 test 186.7466 metric ['186.7466']
2024-06-21 09:34:25.710 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 09:34:25.929 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 09:34:25.940 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 48])
2024-06-21 09:34:25.942 | INFO     | __main__:main:61 - Untrained loss: 201.8755645751953
2024-06-21 09:34:25.942 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 09:34:25.946 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-093425
2024-06-21 09:34:26.426 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 09:34:36.441 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 145.6531 test 120.9928 metric ['120.9928']
2024-06-21 09:34:46.444 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 88.5570 test 58.0775 metric ['58.0775']
2024-06-21 09:34:56.618 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 52.1063 test 48.5084 metric ['48.5085']
2024-06-21 09:35:06.674 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 29.1831 test 24.1390 metric ['24.1390']
2024-06-21 09:35:16.628 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 15.6384 test 13.1509 metric ['13.1509']
2024-06-21 09:35:26.772 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 8.3409 test 8.0473 metric ['8.0473']
2024-06-21 09:35:36.984 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 4.7551 test 4.6640 metric ['4.6640']
2024-06-21 09:35:47.797 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 3.1777 test 2.9047 metric ['2.9047']
2024-06-21 09:35:58.760 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 2.5643 test 2.5006 metric ['2.5006']
2024-06-21 09:36:09.682 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 2.3492 test 2.3816 metric ['2.3816']
2024-06-21 09:36:20.812 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 2.2924 test 2.2535 metric ['2.2535']
2024-06-21 09:36:32.199 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 2.2765 test 2.2436 metric ['2.2436']
2024-06-21 09:36:43.414 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 2.2600 test 2.2386 metric ['2.2386']
2024-06-21 09:36:54.705 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 2.2564 test 2.2765 metric ['2.2765']
2024-06-21 09:36:54.706 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2386, current loss 2.2765.Counter 1/10.
2024-06-21 09:37:06.309 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 2.2442 test 2.2370 metric ['2.2370']
2024-06-21 09:37:18.068 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 2.2373 test 2.2134 metric ['2.2134']
2024-06-21 09:37:29.733 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 2.2414 test 2.2226 metric ['2.2226']
2024-06-21 09:37:29.734 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2134, current loss 2.2226.Counter 1/10.
2024-06-21 09:37:41.481 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 2.2380 test 2.2512 metric ['2.2512']
2024-06-21 09:37:41.482 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2134, current loss 2.2512.Counter 2/10.
2024-06-21 09:37:53.268 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 2.2369 test 2.2196 metric ['2.2196']
2024-06-21 09:37:53.269 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2134, current loss 2.2196.Counter 3/10.
2024-06-21 09:38:04.957 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 2.2231 test 2.2090 metric ['2.2090']
2024-06-21 09:38:16.486 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 2.2388 test 2.2354 metric ['2.2354']
2024-06-21 09:38:16.486 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2090, current loss 2.2354.Counter 1/10.
2024-06-21 09:38:28.174 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 2.2182 test 2.2011 metric ['2.2011']
2024-06-21 09:38:39.675 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 2.2257 test 2.2278 metric ['2.2278']
2024-06-21 09:38:39.676 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2011, current loss 2.2278.Counter 1/10.
2024-06-21 09:38:51.400 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 2.2147 test 2.2232 metric ['2.2232']
2024-06-21 09:38:51.400 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2011, current loss 2.2232.Counter 2/10.
2024-06-21 09:39:03.177 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 2.2165 test 2.2397 metric ['2.2397']
2024-06-21 09:39:03.178 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.2011, current loss 2.2397.Counter 3/10.
2024-06-21 09:39:15.269 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 2.1971 test 2.1996 metric ['2.1996']
2024-06-21 09:39:27.491 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 2.2119 test 2.1901 metric ['2.1901']
2024-06-21 09:39:39.639 | INFO     | mltrainer.trainer:report:191 - Epoch 27 train 2.1930 test 2.2660 metric ['2.2660']
2024-06-21 09:39:39.640 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2660.Counter 1/10.
2024-06-21 09:39:51.865 | INFO     | mltrainer.trainer:report:191 - Epoch 28 train 2.2005 test 2.2446 metric ['2.2446']
2024-06-21 09:39:51.866 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2446.Counter 2/10.
2024-06-21 09:40:04.259 | INFO     | mltrainer.trainer:report:191 - Epoch 29 train 2.1908 test 2.2244 metric ['2.2244']
2024-06-21 09:40:04.259 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2244.Counter 3/10.
2024-06-21 09:40:16.726 | INFO     | mltrainer.trainer:report:191 - Epoch 30 train 2.1860 test 2.1906 metric ['2.1906']
2024-06-21 09:40:16.726 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.1906.Counter 4/10.
2024-06-21 09:40:29.311 | INFO     | mltrainer.trainer:report:191 - Epoch 31 train 2.1768 test 2.2157 metric ['2.2157']
2024-06-21 09:40:29.311 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2157.Counter 5/10.
2024-06-21 09:40:42.002 | INFO     | mltrainer.trainer:report:191 - Epoch 32 train 2.1805 test 2.2348 metric ['2.2348']
2024-06-21 09:40:42.003 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2348.Counter 6/10.
2024-06-21 09:40:54.663 | INFO     | mltrainer.trainer:report:191 - Epoch 33 train 2.1708 test 2.2552 metric ['2.2552']
2024-06-21 09:40:54.664 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2552.Counter 7/10.
2024-06-21 09:41:07.362 | INFO     | mltrainer.trainer:report:191 - Epoch 34 train 2.1724 test 2.2132 metric ['2.2132']
2024-06-21 09:41:07.363 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2132.Counter 8/10.
2024-06-21 09:41:20.135 | INFO     | mltrainer.trainer:report:191 - Epoch 35 train 2.1740 test 2.2477 metric ['2.2477']
2024-06-21 09:41:20.136 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1901, current loss 2.2477.Counter 9/10.
2024-06-21 09:41:32.768 | INFO     | mltrainer.trainer:report:191 - Epoch 36 train 2.1669 test 2.1703 metric ['2.1703']
2024-06-21 09:41:45.729 | INFO     | mltrainer.trainer:report:191 - Epoch 37 train 2.1682 test 2.1766 metric ['2.1766']
2024-06-21 09:41:45.730 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1703, current loss 2.1766.Counter 1/10.
2024-06-21 09:41:58.050 | INFO     | mltrainer.trainer:report:191 - Epoch 38 train 2.1691 test 2.2146 metric ['2.2146']
2024-06-21 09:41:58.051 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1703, current loss 2.2146.Counter 2/10.
2024-06-21 09:42:10.278 | INFO     | mltrainer.trainer:report:191 - Epoch 39 train 2.1438 test 2.1575 metric ['2.1575']
2024-06-21 09:42:22.568 | INFO     | mltrainer.trainer:report:191 - Epoch 40 train 2.1609 test 2.1719 metric ['2.1719']
2024-06-21 09:42:22.568 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1575, current loss 2.1719.Counter 1/10.
2024-06-21 09:42:34.808 | INFO     | mltrainer.trainer:report:191 - Epoch 41 train 2.1502 test 2.1773 metric ['2.1773']
2024-06-21 09:42:34.808 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1575, current loss 2.1773.Counter 2/10.
2024-06-21 09:42:47.115 | INFO     | mltrainer.trainer:report:191 - Epoch 42 train 2.1506 test 2.2058 metric ['2.2058']
2024-06-21 09:42:47.116 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1575, current loss 2.2058.Counter 3/10.
2024-06-21 09:42:59.485 | INFO     | mltrainer.trainer:report:191 - Epoch 43 train 2.1459 test 2.1992 metric ['2.1992']
2024-06-21 09:42:59.485 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1575, current loss 2.1992.Counter 4/10.
2024-06-21 09:43:11.832 | INFO     | mltrainer.trainer:report:191 - Epoch 44 train 2.1402 test 2.1557 metric ['2.1557']
2024-06-21 09:43:24.277 | INFO     | mltrainer.trainer:report:191 - Epoch 45 train 2.1350 test 2.1772 metric ['2.1772']
2024-06-21 09:43:24.277 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1772.Counter 1/10.
2024-06-21 09:43:36.708 | INFO     | mltrainer.trainer:report:191 - Epoch 46 train 2.1349 test 2.1590 metric ['2.1590']
2024-06-21 09:43:36.709 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1590.Counter 2/10.
2024-06-21 09:43:49.253 | INFO     | mltrainer.trainer:report:191 - Epoch 47 train 2.1552 test 2.1644 metric ['2.1644']
2024-06-21 09:43:49.253 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1644.Counter 3/10.
2024-06-21 09:44:01.718 | INFO     | mltrainer.trainer:report:191 - Epoch 48 train 2.1333 test 2.1697 metric ['2.1697']
2024-06-21 09:44:01.719 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1697.Counter 4/10.
2024-06-21 09:44:14.086 | INFO     | mltrainer.trainer:report:191 - Epoch 49 train 2.1373 test 2.2167 metric ['2.2167']
2024-06-21 09:44:14.087 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.2167.Counter 5/10.
2024-06-21 09:44:26.373 | INFO     | mltrainer.trainer:report:191 - Epoch 50 train 2.1257 test 2.1923 metric ['2.1923']
2024-06-21 09:44:26.374 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1923.Counter 6/10.
2024-06-21 09:44:38.480 | INFO     | mltrainer.trainer:report:191 - Epoch 51 train 2.1217 test 2.1582 metric ['2.1582']
2024-06-21 09:44:38.481 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1582.Counter 7/10.
2024-06-21 09:44:50.918 | INFO     | mltrainer.trainer:report:191 - Epoch 52 train 2.1256 test 2.1950 metric ['2.1950']
2024-06-21 09:44:50.919 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1557, current loss 2.1950.Counter 8/10.
2024-06-21 09:45:02.886 | INFO     | mltrainer.trainer:report:191 - Epoch 53 train 2.1243 test 2.1513 metric ['2.1513']
2024-06-21 09:45:15.198 | INFO     | mltrainer.trainer:report:191 - Epoch 54 train 2.1196 test 2.1828 metric ['2.1828']
2024-06-21 09:45:15.199 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1513, current loss 2.1828.Counter 1/10.
2024-06-21 09:45:27.450 | INFO     | mltrainer.trainer:report:191 - Epoch 55 train 2.1054 test 2.2331 metric ['2.2331']
2024-06-21 09:45:27.451 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1513, current loss 2.2331.Counter 2/10.
2024-06-21 09:45:39.745 | INFO     | mltrainer.trainer:report:191 - Epoch 56 train 2.1100 test 2.1769 metric ['2.1769']
2024-06-21 09:45:39.745 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1513, current loss 2.1769.Counter 3/10.
2024-06-21 09:45:52.175 | INFO     | mltrainer.trainer:report:191 - Epoch 57 train 2.1250 test 2.1425 metric ['2.1425']
2024-06-21 09:46:04.600 | INFO     | mltrainer.trainer:report:191 - Epoch 58 train 2.1079 test 2.1979 metric ['2.1979']
2024-06-21 09:46:04.601 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1979.Counter 1/10.
2024-06-21 09:46:17.342 | INFO     | mltrainer.trainer:report:191 - Epoch 59 train 2.0962 test 2.1660 metric ['2.1660']
2024-06-21 09:46:17.342 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1660.Counter 2/10.
2024-06-21 09:46:29.713 | INFO     | mltrainer.trainer:report:191 - Epoch 60 train 2.1220 test 2.1456 metric ['2.1456']
2024-06-21 09:46:29.714 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1456.Counter 3/10.
2024-06-21 09:46:42.133 | INFO     | mltrainer.trainer:report:191 - Epoch 61 train 2.0936 test 2.1617 metric ['2.1617']
2024-06-21 09:46:42.134 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1617.Counter 4/10.
2024-06-21 09:46:54.787 | INFO     | mltrainer.trainer:report:191 - Epoch 62 train 2.1018 test 2.1884 metric ['2.1884']
2024-06-21 09:46:54.787 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1884.Counter 5/10.
2024-06-21 09:47:07.573 | INFO     | mltrainer.trainer:report:191 - Epoch 63 train 2.1022 test 2.1808 metric ['2.1808']
2024-06-21 09:47:07.574 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1808.Counter 6/10.
2024-06-21 09:47:20.422 | INFO     | mltrainer.trainer:report:191 - Epoch 64 train 2.0919 test 2.1632 metric ['2.1632']
2024-06-21 09:47:20.422 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1632.Counter 7/10.
2024-06-21 09:47:32.847 | INFO     | mltrainer.trainer:report:191 - Epoch 65 train 2.1021 test 2.1794 metric ['2.1794']
2024-06-21 09:47:32.848 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1794.Counter 8/10.
2024-06-21 09:47:45.944 | INFO     | mltrainer.trainer:report:191 - Epoch 66 train 2.0851 test 2.1927 metric ['2.1927']
2024-06-21 09:47:45.944 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1927.Counter 9/10.
2024-06-21 09:47:58.327 | INFO     | mltrainer.trainer:report:191 - Epoch 67 train 2.0957 test 2.1555 metric ['2.1555']
2024-06-21 09:47:58.327 | INFO     | mltrainer.trainer:__call__:234 - best loss: 2.1425, current loss 2.1555.Counter 10/10.
2024-06-21 09:47:58.328 | INFO     | mltrainer.trainer:loop:98 - Interrupting loop due to early stopping patience.
2024-06-21 09:47:58.328 | INFO     | mltrainer.trainer:loop:104 - early_stopping_save was false, using latest model.Set to true to retrieve best model.
2024-06-21 09:47:58.335 | SUCCESS  | __main__:main:95 - finished autoencode.py
2024-06-21 10:09:31.868 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:09:32.082 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:10:11.116 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:10:11.336 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:10:11.350 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 48])
2024-06-21 10:10:51.461 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:10:51.679 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:10:51.687 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 48])
2024-06-21 10:12:40.689 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:12:40.903 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:12:40.968 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 377])
2024-06-21 10:13:08.529 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:13:08.744 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:13:08.802 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 377])
2024-06-21 10:13:33.748 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:13:33.963 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:13:34.021 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 377])
2024-06-21 10:13:51.108 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:13:51.358 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:13:51.417 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 377, 1])
2024-06-21 10:14:05.433 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:14:05.649 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:14:05.665 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 189, 1])
2024-06-21 10:14:26.951 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:14:27.174 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:14:27.191 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 193, 1])
2024-06-21 10:14:38.169 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:14:38.409 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:14:38.425 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:14:52.076 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:14:52.290 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:14:52.306 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 193, 1])
2024-06-21 10:15:05.941 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:15:06.174 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:15:06.233 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 383, 1])
2024-06-21 10:15:40.244 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:15:40.459 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:15:40.471 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 99, 1])
2024-06-21 10:15:51.018 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:15:51.235 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:15:51.251 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 193, 1])
2024-06-21 10:16:14.547 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:16:14.777 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 190])
2024-06-21 10:16:14.826 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 761, 1])
2024-06-21 10:16:26.848 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:16:27.094 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:16:27.110 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 193, 1])
2024-06-21 10:16:37.802 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:16:38.026 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:16:38.043 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:16:58.125 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:16:58.357 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:16:58.441 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 585, 1])
2024-06-21 10:17:07.789 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:17:08.008 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:17:08.068 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 391, 1])
2024-06-21 10:17:18.121 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:17:18.335 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:17:18.394 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 391, 1])
2024-06-21 10:17:27.787 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:17:28.091 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:17:28.151 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 391, 1])
2024-06-21 10:17:48.491 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:17:48.788 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:17:48.852 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 377, 1])
2024-06-21 10:17:58.265 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:17:58.490 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:17:58.554 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 379, 1])
2024-06-21 10:18:06.884 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:18:07.100 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:18:07.159 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 383, 1])
2024-06-21 10:18:28.018 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:18:28.252 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:18:28.297 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:19:55.886 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:19:56.126 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:19:56.190 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 377, 1])
2024-06-21 10:21:27.287 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:21:27.501 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:21:27.559 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 379, 1])
2024-06-21 10:21:44.156 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:21:44.439 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:21:44.509 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 383, 1])
2024-06-21 10:21:57.709 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:21:57.932 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:21:57.945 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 99, 1])
2024-06-21 10:22:07.222 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:22:07.438 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:22:07.446 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 52, 1])
2024-06-21 10:22:21.337 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:22:21.562 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:22:21.571 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 54, 1])
2024-06-21 10:22:30.812 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:22:31.024 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:22:31.037 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 101, 1])
2024-06-21 10:22:40.362 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:22:40.572 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:22:40.588 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:23:03.175 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:23:03.410 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:23:03.428 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 99, 1])
2024-06-21 10:23:14.155 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:23:14.383 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:23:14.403 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 101, 1])
2024-06-21 10:23:21.352 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:23:21.571 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:23:21.587 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:23:41.577 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:23:41.815 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:23:41.832 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:24:05.043 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:24:05.258 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:24:05.275 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:24:27.133 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:24:27.349 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:24:27.365 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 197, 1])
2024-06-21 10:24:47.516 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:24:47.727 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:24:47.743 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 10:36:17.487 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:36:17.772 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:36:17.802 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 10:36:17.804 | INFO     | __main__:main:61 - Untrained loss: 6549.646484375
2024-06-21 10:36:30.835 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:36:31.058 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:36:31.075 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 10:36:31.075 | INFO     | __main__:main:61 - Untrained loss: 6822.693359375
2024-06-21 10:36:31.076 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 10:36:46.354 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:36:46.571 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:36:46.586 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 10:36:46.587 | INFO     | __main__:main:61 - Untrained loss: 7283.88720703125
2024-06-21 10:36:46.587 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 10:36:46.591 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-103646
2024-06-21 10:36:47.062 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 10:36:58.677 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 194.5608 test 13.2051 metric ['13.2051']
2024-06-21 10:37:26.358 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 10:37:26.575 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 48])
2024-06-21 10:37:26.591 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 10:37:26.592 | INFO     | __main__:main:61 - Untrained loss: 9317.546875
2024-06-21 10:37:26.592 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 10:37:26.595 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-103726
2024-06-21 10:37:27.060 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 10:37:38.278 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 235.7192 test 11.8843 metric ['11.8843']
2024-06-21 11:56:19.761 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:58:07.478 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:58:40.780 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:59:14.547 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:59:14.754 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 192])
2024-06-21 11:59:33.914 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:59:34.127 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 128, 96])
2024-06-21 11:59:55.158 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 11:59:55.366 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 64, 96])
2024-06-21 12:00:07.027 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:00:07.384 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 96])
2024-06-21 12:00:15.820 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:00:16.036 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 32, 96])
2024-06-21 12:00:25.077 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:00:25.302 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2, 48])
2024-06-21 12:00:38.835 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:00:39.055 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2, 48])
2024-06-21 12:00:39.079 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:24:34.718 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:25:09.436 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:25:09.727 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 24])
2024-06-21 12:25:09.757 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:25:09.759 | INFO     | __main__:main:61 - Untrained loss: 4542.2705078125
2024-06-21 12:25:09.760 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:25:09.768 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122509
2024-06-21 12:25:10.402 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:25:35.879 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 166.5077 test 6.4070 metric ['6.4070']
2024-06-21 12:26:53.049 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:26:53.383 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 23])
2024-06-21 12:26:53.413 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:26:53.414 | INFO     | __main__:main:61 - Untrained loss: 7476.703125
2024-06-21 12:26:53.415 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:26:53.423 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122653
2024-06-21 12:26:54.197 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:27:18.194 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:27:18.559 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 15])
2024-06-21 12:27:18.581 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 129, 1])
2024-06-21 12:27:36.199 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:27:36.483 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 16])
2024-06-21 12:27:36.505 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 137, 1])
2024-06-21 12:27:50.588 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:27:51.076 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 24])
2024-06-21 12:27:51.106 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:27:51.108 | INFO     | __main__:main:61 - Untrained loss: 8761.55859375
2024-06-21 12:27:51.108 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:27:51.113 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122751
2024-06-21 12:27:51.680 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:28:11.769 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:28:12.178 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 23])
2024-06-21 12:28:12.207 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:28:12.209 | INFO     | __main__:main:61 - Untrained loss: 8803.9658203125
2024-06-21 12:28:12.210 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:28:12.219 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122812
2024-06-21 12:28:12.961 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:28:30.766 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:28:31.043 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 15])
2024-06-21 12:28:31.064 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 129, 1])
2024-06-21 12:28:45.331 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:28:45.703 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 12])
2024-06-21 12:28:45.723 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 105, 1])
2024-06-21 12:29:03.919 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:29:04.396 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 23])
2024-06-21 12:29:04.502 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:29:04.514 | INFO     | __main__:main:61 - Untrained loss: 7620.9267578125
2024-06-21 12:29:04.514 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:29:04.523 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122904
2024-06-21 12:29:05.297 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:29:26.723 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:29:27.182 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 11])
2024-06-21 12:29:27.201 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 97, 1])
2024-06-21 12:29:40.417 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:29:40.756 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 21])
2024-06-21 12:29:40.783 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 177, 1])
2024-06-21 12:29:52.328 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:29:52.630 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 23])
2024-06-21 12:29:52.658 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:29:52.660 | INFO     | __main__:main:61 - Untrained loss: 9132.033203125
2024-06-21 12:29:52.661 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:29:52.670 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-122952
2024-06-21 12:29:53.479 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:30:45.354 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:30:45.704 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 24])
2024-06-21 12:30:45.734 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:30:45.736 | INFO     | __main__:main:61 - Untrained loss: 14024.296875
2024-06-21 12:30:45.737 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:30:45.745 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-123045
2024-06-21 12:30:46.551 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:30:58.725 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:30:59.109 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 12])
2024-06-21 12:30:59.128 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 105, 1])
2024-06-21 12:31:23.618 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:31:23.894 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:31:23.905 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 57, 1])
2024-06-21 12:32:21.112 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:32:21.403 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:32:21.503 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 77, 1])
2024-06-21 12:32:45.814 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:32:46.165 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:32:46.201 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:32:46.203 | INFO     | __main__:main:61 - Untrained loss: 8379.4619140625
2024-06-21 12:32:46.203 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:32:46.210 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-123246
2024-06-21 12:32:46.742 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:33:18.039 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 190.0990 test 5.8825 metric ['5.8825']
2024-06-21 12:33:31.418 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:33:31.801 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:33:31.842 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 225, 1])
2024-06-21 12:33:50.790 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:33:51.075 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:33:51.098 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 113, 1])
2024-06-21 12:34:13.446 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:34:13.776 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:34:13.801 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 121, 1])
2024-06-21 12:34:30.863 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:34:31.206 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:34:31.241 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 221, 1])
2024-06-21 12:34:46.583 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:34:46.929 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:34:46.969 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 229, 1])
2024-06-21 12:36:13.310 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:36:13.588 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:36:13.591 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 13, 128])
2024-06-21 12:36:45.546 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:36:45.910 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:36:45.917 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 27, 128])
2024-06-21 12:37:48.466 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:37:48.741 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:37:48.754 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 55, 128])
2024-06-21 12:38:07.207 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:38:07.580 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:38:07.598 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 111, 128])
2024-06-21 12:38:30.671 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:38:31.110 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:38:31.142 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 223, 128])
2024-06-21 12:38:56.525 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:38:56.828 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:38:56.832 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 8, 128])
2024-06-21 12:39:14.597 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:39:14.872 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:39:14.879 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 35, 128])
2024-06-21 12:39:37.234 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:39:37.558 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:39:37.561 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 8, 128])
2024-06-21 12:40:05.644 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:40:05.924 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:40:05.929 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 17, 128])
2024-06-21 12:40:23.452 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:40:23.808 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:40:23.816 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 35, 128])
2024-06-21 12:40:37.988 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:40:38.269 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:40:38.297 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 145, 1])
2024-06-21 12:40:50.973 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:40:51.263 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:40:51.285 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 89, 1])
2024-06-21 12:41:08.059 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:41:08.525 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:41:08.613 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 75, 1])
2024-06-21 12:41:16.305 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:41:16.582 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:41:16.610 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 145, 1])
2024-06-21 12:41:23.694 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:41:24.100 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:41:24.134 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 145, 1])
2024-06-21 12:41:36.222 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:41:36.596 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:41:36.619 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 75, 1])
2024-06-21 12:41:57.782 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:41:58.130 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:41:58.158 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 145, 1])
2024-06-21 12:42:12.720 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:42:13.082 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:42:13.090 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 35, 128])
2024-06-21 12:42:36.681 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:42:36.956 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:42:36.969 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 71, 128])
2024-06-21 12:42:52.139 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:42:52.537 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:42:52.550 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 37, 128])
2024-06-21 12:43:06.860 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:43:07.146 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:43:07.162 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 75, 128])
2024-06-21 12:43:18.470 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:43:18.833 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:43:18.932 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 111, 128])
2024-06-21 12:43:32.625 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:43:32.939 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:43:33.031 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 153, 128])
2024-06-21 12:43:48.334 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:43:48.638 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:43:48.720 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 243, 128])
2024-06-21 12:44:02.655 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:44:02.924 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:44:03.000 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 171, 128])
2024-06-21 12:44:16.622 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:44:16.921 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:44:17.036 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 231, 128])
2024-06-21 12:44:32.232 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:44:32.537 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:44:32.564 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 183, 128])
2024-06-21 12:44:45.335 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:44:45.665 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:44:45.695 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 189, 128])
2024-06-21 12:44:56.629 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:44:56.984 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:44:57.016 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 191, 1])
2024-06-21 12:45:07.927 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:45:08.166 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:45:08.186 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 194, 1])
2024-06-21 12:45:18.681 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:45:18.907 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:45:18.929 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 193, 1])
2024-06-21 12:45:31.339 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 12:45:31.563 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6])
2024-06-21 12:45:31.630 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 192, 1])
2024-06-21 12:45:31.631 | INFO     | __main__:main:61 - Untrained loss: 12466.72265625
2024-06-21 12:45:31.632 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 12:45:31.638 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-124531
2024-06-21 12:45:32.109 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 12:45:47.826 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 159.1950 test 7.9221 metric ['7.9221']
2024-06-21 12:46:03.110 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 5.0817 test 3.3022 metric ['3.3022']
2024-06-21 13:23:39.745 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:24:02.926 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:25:09.489 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:26:56.038 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:27:16.278 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:27:16.491 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:28:15.022 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:28:15.293 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:28:15.481 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 66, 54])
2024-06-21 13:28:41.934 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:28:42.153 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:28:42.306 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 59, 47])
2024-06-21 13:28:56.755 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:28:56.970 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:28:56.985 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 12, 11])
2024-06-21 13:29:20.185 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:29:20.412 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:29:20.448 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 13])
2024-06-21 13:29:45.746 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:29:45.967 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:29:45.989 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 13])
2024-06-21 13:29:59.410 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:29:59.688 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:29:59.729 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 23, 19])
2024-06-21 13:30:32.764 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:30:32.982 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:30:33.000 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 12])
2024-06-21 13:33:10.444 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:33:10.663 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:33:10.675 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 13:33:21.950 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:33:22.179 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 13:33:22.191 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 13:33:22.192 | INFO     | __main__:main:61 - Untrained loss: 12.618125915527344
2024-06-21 13:35:26.013 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 13:35:26.224 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 13:35:26.232 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 32, 16])
2024-06-21 14:20:38.963 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:20:39.178 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:21:06.432 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:21:06.640 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:21:06.647 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 32, 16])
2024-06-21 14:21:35.603 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:21:35.807 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:21:35.812 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 12])
2024-06-21 14:21:51.016 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:21:51.224 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:21:51.226 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 32, 4, 2])
2024-06-21 14:22:35.004 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:22:35.212 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:22:35.215 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 5, 3])
2024-06-21 14:22:55.451 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:22:55.655 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:22:55.660 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 12])
2024-06-21 14:24:36.435 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:24:36.649 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:24:36.656 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 7])
2024-06-21 14:25:04.234 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:25:04.443 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:25:04.444 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 32, 4, 2])
2024-06-21 14:25:17.772 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:25:17.981 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:25:17.984 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 7, 3])
2024-06-21 14:25:32.508 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:25:32.716 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:25:32.718 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 5, 1])
2024-06-21 14:26:24.253 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:26:24.465 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:26:24.468 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 9, 5])
2024-06-21 14:27:01.185 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:27:01.402 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:27:01.405 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 6, 4])
2024-06-21 14:27:12.688 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:27:12.894 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:27:12.898 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 12, 6])
2024-06-21 14:27:33.167 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:27:33.379 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:27:33.383 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 9, 5])
2024-06-21 14:31:18.801 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:31:19.011 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:31:19.013 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 64, 9, 5])
2024-06-21 14:32:06.472 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:32:06.677 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:32:06.685 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 11])
2024-06-21 14:32:21.610 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:32:21.819 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:32:21.829 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 34, 20])
2024-06-21 14:32:38.833 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:32:39.043 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:32:39.056 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 34, 18])
2024-06-21 14:34:24.576 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:34:24.824 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 2, 1])
2024-06-21 14:34:24.827 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 8, 4])
2024-06-21 14:35:03.329 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:35:03.539 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:35:03.568 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 66, 50])
2024-06-21 14:35:31.385 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:35:31.630 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:36:15.661 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:36:15.924 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:36:55.435 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:36:55.656 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:02.747 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:39:03.027 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:03.036 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 34, 26])
2024-06-21 14:39:16.232 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:39:16.441 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:16.479 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 66, 50])
2024-06-21 14:39:29.009 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:39:29.214 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:29.251 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 74, 58])
2024-06-21 14:39:40.732 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:39:40.967 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:41.067 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 98, 74])
2024-06-21 14:39:53.523 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:39:53.732 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:39:53.754 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 50, 42])
2024-06-21 14:40:04.581 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:40:04.788 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:40:04.800 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 30, 26])
2024-06-21 14:40:15.594 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:40:15.800 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:40:15.810 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 14])
2024-06-21 14:40:28.238 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:40:28.442 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:40:28.451 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 18])
2024-06-21 14:40:39.195 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:40:39.457 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:40:39.466 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 14])
2024-06-21 14:42:01.630 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:42:01.836 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:42:01.841 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 8, 6])
2024-06-21 14:42:26.018 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:42:26.276 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:42:26.284 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 7, 5])
2024-06-21 14:42:36.131 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:42:36.346 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:42:36.352 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 9, 7])
2024-06-21 14:42:45.155 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:42:45.418 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:42:45.425 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 8, 6])
2024-06-21 14:43:00.652 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:00.857 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:00.862 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 5, 4])
2024-06-21 14:43:10.147 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:10.358 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:10.363 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 11, 8])
2024-06-21 14:43:19.222 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:19.427 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:19.432 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:43:28.033 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:28.243 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:28.249 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 12])
2024-06-21 14:43:36.553 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:36.764 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:36.771 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 14])
2024-06-21 14:43:48.115 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:48.400 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:48.405 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 32, 22])
2024-06-21 14:43:59.720 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:43:59.930 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:43:59.935 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 8, 6])
2024-06-21 14:44:11.702 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:44:11.909 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:44:11.916 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:44:21.564 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:44:21.775 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:44:21.783 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 26, 18])
2024-06-21 14:44:32.610 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:44:32.834 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:44:32.840 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:44:42.813 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:44:43.039 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:44:43.045 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:44:49.827 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:44:50.031 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:44:50.036 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:45:00.112 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:00.316 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:00.321 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 14])
2024-06-21 14:45:16.699 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:16.917 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:16.923 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 26, 20])
2024-06-21 14:45:26.397 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:26.605 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:26.612 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 32, 26])
2024-06-21 14:45:38.901 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:39.109 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:39.115 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 14])
2024-06-21 14:45:47.567 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:47.771 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:47.777 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 12])
2024-06-21 14:45:57.386 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:45:57.589 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:45:57.640 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 10])
2024-06-21 14:46:08.481 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:46:08.687 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:46:08.739 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 10, 4])
2024-06-21 14:46:19.574 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:46:19.780 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:46:32.764 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:46:32.982 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:46:32.988 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 11, 5])
2024-06-21 14:46:38.781 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:46:38.987 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:46:38.992 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 11, 5])
2024-06-21 14:46:52.791 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:46:53.001 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:46:53.007 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 7])
2024-06-21 14:47:10.831 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:47:11.036 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:47:11.042 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 19, 13])
2024-06-21 14:47:25.510 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:47:25.714 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:47:25.719 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 14])
2024-06-21 14:47:35.065 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:47:35.273 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:47:35.279 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 23, 17])
2024-06-21 14:47:46.983 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:47:47.214 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:47:47.219 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 11])
2024-06-21 14:47:59.726 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:47:59.932 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:47:59.938 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 11])
2024-06-21 14:48:06.848 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:48:07.056 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:48:07.061 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 11])
2024-06-21 14:48:19.197 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:48:19.406 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:48:19.412 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 12])
2024-06-21 14:48:24.956 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:48:25.231 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:48:25.240 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 12])
2024-06-21 14:49:47.882 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:49:48.084 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:50:22.910 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:50:23.119 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:51:03.887 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:51:04.092 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:51:04.098 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 19, 12])
2024-06-21 14:51:33.112 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:51:33.313 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:51:33.318 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 12])
2024-06-21 14:51:53.738 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:51:53.947 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:51:53.953 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:52:11.562 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:52:11.772 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:52:11.778 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 12, 8])
2024-06-21 14:52:28.507 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:52:28.711 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:52:28.716 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 11, 7])
2024-06-21 14:52:40.994 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:52:41.206 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:52:41.213 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:52:56.928 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:52:57.132 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:52:57.138 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 25, 17])
2024-06-21 14:53:12.025 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:53:12.244 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:53:12.252 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:53:26.690 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:53:26.896 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:53:26.903 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 25, 17])
2024-06-21 14:53:48.560 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:53:48.770 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:53:48.775 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 9])
2024-06-21 14:54:12.101 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:54:12.304 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:54:12.309 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:54:37.723 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:54:37.927 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:54:59.134 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:54:59.379 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:55:24.219 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:55:24.425 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:55:53.476 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:55:53.681 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:55:53.686 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:56:21.384 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:56:21.594 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:56:21.601 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 25, 17])
2024-06-21 14:56:37.335 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:56:37.598 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:56:37.605 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:56:52.767 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:56:52.973 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:56:52.979 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 14:57:32.266 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:57:32.472 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:57:32.479 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 11])
2024-06-21 14:57:43.564 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:57:43.773 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:57:43.781 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 13])
2024-06-21 14:57:57.262 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:57:57.467 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:57:57.475 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 11])
2024-06-21 14:58:08.761 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:58:08.968 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:58:08.974 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 14:58:20.983 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:58:21.194 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:58:21.203 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 11])
2024-06-21 14:58:45.190 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:58:45.399 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:58:59.023 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:58:59.231 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:58:59.239 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 13])
2024-06-21 14:59:18.950 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 14:59:19.160 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 16, 4, 3])
2024-06-21 14:59:19.169 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 14:59:19.171 | INFO     | __main__:main:61 - Untrained loss: 24.409332275390625
2024-06-21 14:59:19.171 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 14:59:19.177 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-145919
2024-06-21 14:59:19.680 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 14:59:24.376 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.5204 test 0.0397 metric ['0.0397']
2024-06-21 14:59:28.934 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 0.0294 test 0.0216 metric ['0.0216']
2024-06-21 15:11:44.450 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:12:15.338 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:12:31.691 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:12:31.924 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2, 4, 3])
2024-06-21 15:12:31.934 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 15:12:31.934 | INFO     | __main__:main:61 - Untrained loss: 15.395301818847656
2024-06-21 15:12:31.935 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 15:12:31.938 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-151231
2024-06-21 15:12:32.407 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 15:12:36.849 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.4228 test 0.0356 metric ['0.0356']
2024-06-21 15:13:03.880 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:13:20.796 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:13:21.004 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 3])
2024-06-21 15:13:21.011 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 15:13:21.012 | INFO     | __main__:main:61 - Untrained loss: 15.839435577392578
2024-06-21 15:13:21.012 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 15:13:21.015 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-151321
2024-06-21 15:13:21.525 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 15:13:25.825 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.2862 test 0.0210 metric ['0.0210']
2024-06-21 15:13:30.300 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 0.0211 test 0.0168 metric ['0.0168']
2024-06-21 15:13:35.275 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 0.0176 test 0.0167 metric ['0.0167']
2024-06-21 15:13:39.679 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 0.0165 test 0.0149 metric ['0.0149']
2024-06-21 15:13:44.578 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 0.0160 test 0.0142 metric ['0.0142']
2024-06-21 15:13:48.988 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 0.0159 test 0.0154 metric ['0.0154']
2024-06-21 15:13:48.989 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0142, current loss 0.0154.Counter 1/10.
2024-06-21 15:37:05.725 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:37:05.927 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 2, 1])
2024-06-21 15:37:05.931 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 8, 4])
2024-06-21 15:37:44.394 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:37:44.649 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 3, 2])
2024-06-21 15:37:44.659 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 12, 8])
2024-06-21 15:37:57.872 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:37:58.117 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 3, 2])
2024-06-21 15:37:58.127 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 12, 8])
2024-06-21 15:38:11.038 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:38:11.246 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 6, 4])
2024-06-21 15:38:11.258 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 24, 16])
2024-06-21 15:38:21.648 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:38:21.851 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 5, 3])
2024-06-21 15:38:21.859 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 12])
2024-06-21 15:38:34.877 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:38:35.082 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 4, 2])
2024-06-21 15:38:35.088 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 8])
2024-06-21 15:39:06.423 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:39:06.661 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 7, 5])
2024-06-21 15:39:06.689 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 28, 20])
2024-06-21 15:39:30.416 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:39:30.693 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 35])
2024-06-21 15:40:10.543 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:40:10.747 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:41:56.541 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:41:56.768 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:41:56.786 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 28])
2024-06-21 15:42:25.415 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:42:25.618 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:42:25.638 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 20, 28])
2024-06-21 15:42:45.350 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:42:45.624 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:42:45.649 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 19, 27])
2024-06-21 15:42:58.312 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:42:58.518 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:42:58.532 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 17, 25])
2024-06-21 15:43:12.730 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:43:12.938 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:43:12.943 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 5, 7])
2024-06-21 15:43:28.689 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:43:28.893 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:43:28.901 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 9, 13])
2024-06-21 15:44:10.796 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:44:11.011 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:44:11.012 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 5, 7])
2024-06-21 15:44:48.537 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:44:48.747 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:44:48.749 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 5, 7])
2024-06-21 15:46:17.451 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:46:17.655 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:46:46.339 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:46:46.545 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:46:46.549 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 32, 9, 13])
2024-06-21 15:50:24.232 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:50:24.436 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:50:24.444 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 9, 13])
2024-06-21 15:50:39.643 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:50:39.847 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:50:39.854 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 15:51:01.420 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:51:01.625 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:51:01.633 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 25, 17])
2024-06-21 15:51:13.363 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:51:13.574 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:51:13.592 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 49, 33])
2024-06-21 15:51:25.586 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:51:25.819 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:51:25.826 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 15:51:36.300 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:51:36.503 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:51:36.509 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 19, 13])
2024-06-21 15:51:49.455 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:51:49.661 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:51:49.666 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 18, 12])
2024-06-21 15:52:01.389 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:01.594 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:01.599 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 15, 9])
2024-06-21 15:52:13.435 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:13.641 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:13.647 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 10, 6])
2024-06-21 15:52:26.246 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:26.453 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:26.458 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 12, 8])
2024-06-21 15:52:35.827 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:36.033 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:36.039 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 13, 9])
2024-06-21 15:52:46.690 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:46.895 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:46.902 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 14, 10])
2024-06-21 15:52:56.395 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 15:52:56.637 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 2])
2024-06-21 15:52:56.645 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 15:52:56.646 | INFO     | __main__:main:61 - Untrained loss: 4.746077537536621
2024-06-21 15:52:56.646 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 15:52:56.649 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-155256
2024-06-21 15:52:57.118 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 15:53:00.879 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.0816 test 0.0183 metric ['0.0183']
2024-06-21 22:37:57.295 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 22:37:57.619 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 7, 5])
2024-06-21 22:38:18.416 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 22:38:18.614 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 7, 5])
2024-06-21 22:38:18.618 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 22:38:18.633 | INFO     | __main__:main:61 - Untrained loss: 1.4723161458969116
2024-06-21 22:38:18.633 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 22:38:18.636 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-223818
2024-06-21 22:38:19.116 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 22:38:20.944 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.3017 test 0.0238 metric ['0.0238']
2024-06-21 22:38:22.800 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 0.0526 test 0.0210 metric ['0.0210']
2024-06-21 22:38:24.687 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 0.0234 test 0.0186 metric ['0.0186']
2024-06-21 22:38:26.585 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 0.0180 test 0.0172 metric ['0.0172']
2024-06-21 22:38:28.455 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 0.0162 test 0.0167 metric ['0.0167']
2024-06-21 22:41:42.116 | INFO     | __main__:main:24 - starting exam.py
2024-06-21 22:41:42.317 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1])
2024-06-21 22:41:42.321 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-21 22:41:42.322 | INFO     | __main__:main:61 - Untrained loss: 1.6059437990188599
2024-06-21 22:41:42.322 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-21 22:41:42.326 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240621-224142
2024-06-21 22:41:42.796 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-21 22:41:44.900 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.4023 test 0.0296 metric ['0.0296']
2024-06-21 22:41:47.067 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 0.0648 test 0.0236 metric ['0.0236']
2024-06-21 22:42:22.905 | INFO     | __main__:main:24 - starting exam.py
2024-06-22 17:48:33.118 | INFO     | __main__:main:24 - starting exam.py
2024-06-22 17:48:34.511 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 7, 5])
2024-06-22 17:48:34.570 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 16, 12])
2024-06-22 17:48:34.614 | INFO     | __main__:main:61 - Untrained loss: 3.416046380996704
2024-06-22 17:48:34.614 | INFO     | __main__:main:63 - starting training for 100 epochs
2024-06-22 17:48:34.618 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240622-174834
2024-06-22 17:48:35.509 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-22 17:48:38.913 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 0.7541 test 0.0249 metric ['0.0249']
2024-06-22 17:48:42.083 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 0.1445 test 0.0196 metric ['0.0196']
2024-06-22 17:48:45.304 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 0.0443 test 0.0184 metric ['0.0184']
2024-06-22 17:48:48.410 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 0.0248 test 0.0180 metric ['0.0180']
2024-06-22 17:48:51.616 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 0.0207 test 0.0173 metric ['0.0173']
2024-06-22 17:48:54.821 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 0.0193 test 0.0171 metric ['0.0171']
2024-06-22 17:48:57.978 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 0.0185 test 0.0162 metric ['0.0162']
2024-06-22 17:49:01.214 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 0.0176 test 0.0157 metric ['0.0157']
2024-06-22 17:49:04.460 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 0.0169 test 0.0150 metric ['0.0150']
2024-06-22 17:49:07.724 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 0.0163 test 0.0154 metric ['0.0154']
2024-06-22 17:49:07.725 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0150, current loss 0.0154.Counter 1/10.
2024-06-22 17:49:11.019 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 0.0158 test 0.0141 metric ['0.0141']
2024-06-22 17:49:14.374 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 0.0153 test 0.0144 metric ['0.0144']
2024-06-22 17:49:14.375 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0141, current loss 0.0144.Counter 1/10.
2024-06-22 17:49:17.470 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 0.0147 test 0.0137 metric ['0.0137']
2024-06-22 17:49:20.589 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 0.0143 test 0.0137 metric ['0.0137']
2024-06-22 17:49:20.589 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0137, current loss 0.0137.Counter 1/10.
2024-06-22 17:49:23.737 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 0.0136 test 0.0129 metric ['0.0129']
2024-06-22 17:49:26.858 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 0.0131 test 0.0128 metric ['0.0128']
2024-06-22 17:49:29.961 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 0.0128 test 0.0122 metric ['0.0122']
2024-06-22 17:49:33.065 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 0.0123 test 0.0120 metric ['0.0120']
2024-06-22 17:49:36.198 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 0.0119 test 0.0115 metric ['0.0115']
2024-06-22 17:49:39.466 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 0.0115 test 0.0112 metric ['0.0112']
2024-06-22 17:49:42.598 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 0.0112 test 0.0100 metric ['0.0100']
2024-06-22 17:49:45.958 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 0.0107 test 0.0094 metric ['0.0094']
2024-06-22 17:49:48.980 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 0.0106 test 0.0101 metric ['0.0101']
2024-06-22 17:49:48.981 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0094, current loss 0.0101.Counter 1/10.
2024-06-22 17:49:52.147 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 0.0102 test 0.0096 metric ['0.0096']
2024-06-22 17:49:52.147 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0094, current loss 0.0096.Counter 2/10.
2024-06-22 17:49:55.231 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 0.0102 test 0.0091 metric ['0.0091']
2024-06-22 17:49:58.366 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 0.0099 test 0.0090 metric ['0.0090']
2024-06-22 17:50:01.506 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 0.0097 test 0.0091 metric ['0.0091']
2024-06-22 17:50:01.507 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0090, current loss 0.0091.Counter 1/10.
2024-06-22 17:50:04.588 | INFO     | mltrainer.trainer:report:191 - Epoch 27 train 0.0095 test 0.0085 metric ['0.0085']
2024-06-22 17:50:07.755 | INFO     | mltrainer.trainer:report:191 - Epoch 28 train 0.0094 test 0.0087 metric ['0.0087']
2024-06-22 17:50:07.756 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0085, current loss 0.0087.Counter 1/10.
2024-06-22 17:50:10.862 | INFO     | mltrainer.trainer:report:191 - Epoch 29 train 0.0091 test 0.0089 metric ['0.0089']
2024-06-22 17:50:10.863 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0085, current loss 0.0089.Counter 2/10.
2024-06-22 17:50:14.117 | INFO     | mltrainer.trainer:report:191 - Epoch 30 train 0.0090 test 0.0086 metric ['0.0086']
2024-06-22 17:50:14.117 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0085, current loss 0.0086.Counter 3/10.
2024-06-22 17:50:17.184 | INFO     | mltrainer.trainer:report:191 - Epoch 31 train 0.0089 test 0.0088 metric ['0.0088']
2024-06-22 17:50:17.185 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0085, current loss 0.0088.Counter 4/10.
2024-06-22 17:50:20.406 | INFO     | mltrainer.trainer:report:191 - Epoch 32 train 0.0086 test 0.0083 metric ['0.0083']
2024-06-22 17:50:23.468 | INFO     | mltrainer.trainer:report:191 - Epoch 33 train 0.0086 test 0.0083 metric ['0.0083']
2024-06-22 17:50:23.468 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0083, current loss 0.0083.Counter 1/10.
2024-06-22 17:50:26.616 | INFO     | mltrainer.trainer:report:191 - Epoch 34 train 0.0084 test 0.0078 metric ['0.0078']
2024-06-22 17:50:29.757 | INFO     | mltrainer.trainer:report:191 - Epoch 35 train 0.0084 test 0.0084 metric ['0.0084']
2024-06-22 17:50:29.757 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0078, current loss 0.0084.Counter 1/10.
2024-06-22 17:50:32.816 | INFO     | mltrainer.trainer:report:191 - Epoch 36 train 0.0083 test 0.0079 metric ['0.0079']
2024-06-22 17:50:32.816 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0078, current loss 0.0079.Counter 2/10.
2024-06-22 17:50:35.943 | INFO     | mltrainer.trainer:report:191 - Epoch 37 train 0.0081 test 0.0090 metric ['0.0090']
2024-06-22 17:50:35.943 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0078, current loss 0.0090.Counter 3/10.
2024-06-22 17:50:39.063 | INFO     | mltrainer.trainer:report:191 - Epoch 38 train 0.0082 test 0.0078 metric ['0.0078']
2024-06-22 17:50:39.064 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0078, current loss 0.0078.Counter 4/10.
2024-06-22 17:50:42.172 | INFO     | mltrainer.trainer:report:191 - Epoch 39 train 0.0080 test 0.0075 metric ['0.0075']
2024-06-22 17:50:45.300 | INFO     | mltrainer.trainer:report:191 - Epoch 40 train 0.0080 test 0.0084 metric ['0.0084']
2024-06-22 17:50:45.301 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0075, current loss 0.0084.Counter 1/10.
2024-06-22 17:50:48.354 | INFO     | mltrainer.trainer:report:191 - Epoch 41 train 0.0079 test 0.0088 metric ['0.0088']
2024-06-22 17:50:48.355 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0075, current loss 0.0088.Counter 2/10.
2024-06-22 17:50:51.505 | INFO     | mltrainer.trainer:report:191 - Epoch 42 train 0.0078 test 0.0075 metric ['0.0075']
2024-06-22 17:50:51.505 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0075, current loss 0.0075.Counter 3/10.
2024-06-22 17:50:54.672 | INFO     | mltrainer.trainer:report:191 - Epoch 43 train 0.0078 test 0.0088 metric ['0.0088']
2024-06-22 17:50:54.673 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0075, current loss 0.0088.Counter 4/10.
2024-06-22 17:50:57.720 | INFO     | mltrainer.trainer:report:191 - Epoch 44 train 0.0079 test 0.0083 metric ['0.0083']
2024-06-22 17:50:57.720 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0075, current loss 0.0083.Counter 5/10.
2024-06-22 17:51:00.864 | INFO     | mltrainer.trainer:report:191 - Epoch 45 train 0.0078 test 0.0074 metric ['0.0074']
2024-06-22 17:51:04.033 | INFO     | mltrainer.trainer:report:191 - Epoch 46 train 0.0076 test 0.0078 metric ['0.0078']
2024-06-22 17:51:04.034 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0074, current loss 0.0078.Counter 1/10.
2024-06-22 17:51:10.502 | INFO     | mltrainer.trainer:report:191 - Epoch 47 train 0.0076 test 0.0080 metric ['0.0080']
2024-06-22 17:51:10.503 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0074, current loss 0.0080.Counter 2/10.
2024-06-22 17:51:24.962 | INFO     | mltrainer.trainer:report:191 - Epoch 48 train 0.0076 test 0.0078 metric ['0.0078']
2024-06-22 17:51:24.963 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0074, current loss 0.0078.Counter 3/10.
2024-06-22 17:51:30.711 | INFO     | mltrainer.trainer:report:191 - Epoch 49 train 0.0076 test 0.0071 metric ['0.0071']
2024-06-22 17:51:34.955 | INFO     | mltrainer.trainer:report:191 - Epoch 50 train 0.0075 test 0.0075 metric ['0.0075']
2024-06-22 17:51:34.955 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0071, current loss 0.0075.Counter 1/10.
2024-06-22 17:51:38.155 | INFO     | mltrainer.trainer:report:191 - Epoch 51 train 0.0075 test 0.0067 metric ['0.0067']
2024-06-22 17:51:41.354 | INFO     | mltrainer.trainer:report:191 - Epoch 52 train 0.0075 test 0.0076 metric ['0.0076']
2024-06-22 17:51:41.354 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0076.Counter 1/10.
2024-06-22 17:51:44.513 | INFO     | mltrainer.trainer:report:191 - Epoch 53 train 0.0074 test 0.0078 metric ['0.0078']
2024-06-22 17:51:44.514 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0078.Counter 2/10.
2024-06-22 17:51:47.811 | INFO     | mltrainer.trainer:report:191 - Epoch 54 train 0.0074 test 0.0088 metric ['0.0088']
2024-06-22 17:51:47.812 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0088.Counter 3/10.
2024-06-22 17:51:51.089 | INFO     | mltrainer.trainer:report:191 - Epoch 55 train 0.0074 test 0.0087 metric ['0.0087']
2024-06-22 17:51:51.090 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0087.Counter 4/10.
2024-06-22 17:51:54.427 | INFO     | mltrainer.trainer:report:191 - Epoch 56 train 0.0075 test 0.0076 metric ['0.0076']
2024-06-22 17:51:54.428 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0076.Counter 5/10.
2024-06-22 17:51:57.708 | INFO     | mltrainer.trainer:report:191 - Epoch 57 train 0.0072 test 0.0069 metric ['0.0069']
2024-06-22 17:51:57.709 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0069.Counter 6/10.
2024-06-22 17:52:01.100 | INFO     | mltrainer.trainer:report:191 - Epoch 58 train 0.0072 test 0.0069 metric ['0.0069']
2024-06-22 17:52:01.101 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0069.Counter 7/10.
2024-06-22 17:52:04.320 | INFO     | mltrainer.trainer:report:191 - Epoch 59 train 0.0073 test 0.0073 metric ['0.0073']
2024-06-22 17:52:04.321 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0073.Counter 8/10.
2024-06-22 17:52:07.557 | INFO     | mltrainer.trainer:report:191 - Epoch 60 train 0.0073 test 0.0081 metric ['0.0081']
2024-06-22 17:52:07.558 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0081.Counter 9/10.
2024-06-22 17:52:11.139 | INFO     | mltrainer.trainer:report:191 - Epoch 61 train 0.0073 test 0.0087 metric ['0.0087']
2024-06-22 17:52:11.140 | INFO     | mltrainer.trainer:__call__:234 - best loss: 0.0067, current loss 0.0087.Counter 10/10.
2024-06-22 17:52:11.140 | INFO     | mltrainer.trainer:loop:98 - Interrupting loop due to early stopping patience.
2024-06-22 17:52:11.141 | INFO     | mltrainer.trainer:loop:104 - early_stopping_save was false, using latest model.Set to true to retrieve best model.
2024-06-22 17:52:11.147 | SUCCESS  | __main__:main:96 - finished autoencode.py
2024-06-23 20:35:16.294 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:35:34.761 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:35:57.268 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:36:27.612 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:37:13.265 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:37:35.345 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:38:01.505 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:38:15.094 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:38:31.123 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:40:01.855 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:40:21.299 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:40:59.260 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:44:38.911 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:44:39.338 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:45:00.345 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:45:00.841 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:46:31.982 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:46:32.529 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:47:08.891 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:47:09.307 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:49:40.544 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:49:40.984 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:50:01.983 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:50:02.475 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:51:40.813 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:51:41.273 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:51:54.420 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:51:54.805 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:53:48.011 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:53:48.532 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:55:09.643 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:55:29.933 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:55:30.352 | INFO     | __main__:main:54 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:55:30.360 | INFO     | __main__:main:57 - the shape after: torch.Size([32, 1, 1])
2024-06-23 20:56:09.135 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:56:21.441 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:56:21.718 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 20:56:21.867 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:56:21.875 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 20:57:20.358 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:57:44.261 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:58:05.772 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:58:06.026 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 20:58:06.179 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:58:06.183 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 20:59:07.464 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 20:59:07.733 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 20:59:07.878 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 20:59:07.883 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 21:01:44.394 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:01:44.688 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:01:44.840 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:02:31.949 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:02:32.261 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:02:32.420 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:03:16.021 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:03:16.354 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:03:16.733 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:03:16.758 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 64])
2024-06-23 21:04:10.619 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:04:10.903 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:04:11.114 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:04:38.952 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:04:39.208 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:04:39.356 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:05:20.294 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:05:20.538 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:05:20.682 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:05:20.686 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1])
2024-06-23 21:06:01.191 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:06:01.474 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:06:01.629 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:06:41.758 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:06:42.005 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:06:42.159 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:06:42.166 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1])
2024-06-23 21:06:57.553 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:06:57.815 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:06:57.975 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:07:25.010 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:07:25.264 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:07:25.421 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:07:25.426 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1])
2024-06-23 21:07:53.676 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:07:54.001 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:07:54.262 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:07:54.273 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1])
2024-06-23 21:08:05.760 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:08:06.007 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:08:06.164 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:08:06.169 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1])
2024-06-23 21:12:17.823 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:12:18.108 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:12:18.331 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:14:34.436 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:14:34.722 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:14:34.924 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:16:03.999 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:16:04.256 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:16:04.947 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:19:19.395 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:19:19.698 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:19:19.843 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:19:19.851 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 21:19:42.178 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:19:42.465 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:19:42.617 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:19:42.621 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 21:19:55.617 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:19:55.865 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:19:56.310 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:19:56.314 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 21:19:56.331 | INFO     | __main__:main:63 - Untrained loss: 10.077102661132812
2024-06-23 21:20:32.635 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:20:32.898 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:20:33.045 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:20:49.503 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:20:49.771 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:20:49.928 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:21:20.724 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:21:20.989 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:21:21.173 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:21:32.809 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:21:33.072 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:21:33.475 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:21:57.829 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:21:58.073 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:21:58.230 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:22:19.984 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:22:20.293 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:22:20.739 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:22:20.744 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:22:58.198 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:22:58.447 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:22:59.047 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:22:59.104 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:22:59.105 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:22:59.106 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:23:22.932 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:23:23.211 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:23:23.455 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:23:23.515 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:23:23.518 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:23:48.522 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:23:48.783 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:23:49.389 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:23:49.395 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:23:49.431 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:24:03.945 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:24:04.227 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:24:04.365 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:24:04.369 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:24:04.382 | INFO     | __main__:main:63 - Untrained loss: 9.18523120880127
2024-06-23 21:29:48.470 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:29:48.709 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:29:48.861 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:32:47.859 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:32:48.102 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:32:48.242 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:33:19.352 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:33:19.679 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:33:20.233 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:33:20.239 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-23 21:33:20.246 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:33:38.362 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:33:38.634 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:33:38.962 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:33:38.966 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:33:38.967 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:34:00.359 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:34:00.657 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:34:00.808 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:34:00.815 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:34:00.816 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:35:18.696 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:35:19.006 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:35:19.334 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:35:19.345 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:35:19.347 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:35:43.685 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:35:43.955 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:35:44.096 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:35:44.101 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:35:44.102 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:36:37.567 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:36:37.839 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:36:38.003 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:36:38.008 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:36:38.009 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-23 21:38:24.517 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:38:24.770 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:38:24.935 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:38:24.979 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:38:24.981 | INFO     | __main__:main:63 - Untrained loss: 16.85944366455078
2024-06-23 21:38:53.882 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:38:54.149 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:38:54.306 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:38:54.586 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:38:54.588 | INFO     | __main__:main:63 - Untrained loss: 7.337217807769775
2024-06-23 21:38:54.589 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:40:00.060 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:40:00.318 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:40:00.461 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:40:00.530 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:40:00.531 | INFO     | __main__:main:63 - Untrained loss: 10.674921035766602
2024-06-23 21:40:00.532 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:40:24.060 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:40:24.330 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:40:24.480 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:40:24.534 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:40:24.535 | INFO     | __main__:main:63 - Untrained loss: 5.843225479125977
2024-06-23 21:40:24.535 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:40:49.407 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:40:49.686 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:40:49.879 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:40:49.929 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:40:49.931 | INFO     | __main__:main:63 - Untrained loss: 18.269397735595703
2024-06-23 21:40:49.932 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:41:15.491 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:41:15.758 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:41:15.910 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:41:15.958 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:41:15.960 | INFO     | __main__:main:63 - Untrained loss: 7.854163646697998
2024-06-23 21:41:15.961 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:42:30.960 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:42:31.217 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:42:31.357 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 21:42:31.410 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:42:31.412 | INFO     | __main__:main:63 - Untrained loss: 11.4158353805542
2024-06-23 21:42:31.412 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:42:31.420 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-214231
2024-06-23 21:42:32.399 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 21:43:47.665 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 21:43:47.932 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 21:43:48.062 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 16])
2024-06-23 21:43:48.080 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 21:43:48.082 | INFO     | __main__:main:63 - Untrained loss: 25.58481216430664
2024-06-23 21:43:48.083 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 21:43:48.091 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-214348
2024-06-23 21:43:49.134 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 21:46:28.491 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 6.0548 test 5.4685 metric ['5.4685']
2024-06-23 21:47:35.169 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 5.2878 test 5.2130 metric ['5.2130']
2024-06-23 21:48:41.522 | INFO     | mltrainer.trainer:report:191 - Epoch 2 train 5.1976 test 4.4298 metric ['4.4298']
2024-06-23 21:49:54.505 | INFO     | mltrainer.trainer:report:191 - Epoch 3 train 3.9049 test 3.7681 metric ['3.7681']
2024-06-23 21:51:03.727 | INFO     | mltrainer.trainer:report:191 - Epoch 4 train 3.6812 test 3.5486 metric ['3.5486']
2024-06-23 21:52:06.711 | INFO     | mltrainer.trainer:report:191 - Epoch 5 train 3.5741 test 3.5384 metric ['3.5384']
2024-06-23 21:53:11.531 | INFO     | mltrainer.trainer:report:191 - Epoch 6 train 3.5286 test 3.5122 metric ['3.5122']
2024-06-23 21:54:19.983 | INFO     | mltrainer.trainer:report:191 - Epoch 7 train 3.5511 test 3.5264 metric ['3.5264']
2024-06-23 21:54:19.984 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.5122, current loss 3.5264.Counter 1/10.
2024-06-23 21:55:24.726 | INFO     | mltrainer.trainer:report:191 - Epoch 8 train 3.5059 test 3.5865 metric ['3.5865']
2024-06-23 21:55:24.728 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.5122, current loss 3.5865.Counter 2/10.
2024-06-23 21:56:32.118 | INFO     | mltrainer.trainer:report:191 - Epoch 9 train 3.5364 test 3.5107 metric ['3.5107']
2024-06-23 21:57:40.796 | INFO     | mltrainer.trainer:report:191 - Epoch 10 train 3.5254 test 3.5401 metric ['3.5401']
2024-06-23 21:57:40.797 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.5107, current loss 3.5401.Counter 1/10.
2024-06-23 21:58:50.626 | INFO     | mltrainer.trainer:report:191 - Epoch 11 train 3.5227 test 3.4857 metric ['3.4857']
2024-06-23 21:59:58.907 | INFO     | mltrainer.trainer:report:191 - Epoch 12 train 3.5313 test 3.4905 metric ['3.4905']
2024-06-23 21:59:58.907 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4857, current loss 3.4905.Counter 1/10.
2024-06-23 22:01:08.702 | INFO     | mltrainer.trainer:report:191 - Epoch 13 train 3.5151 test 3.5422 metric ['3.5422']
2024-06-23 22:01:08.704 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4857, current loss 3.5422.Counter 2/10.
2024-06-23 22:02:13.604 | INFO     | mltrainer.trainer:report:191 - Epoch 14 train 3.5084 test 3.5248 metric ['3.5248']
2024-06-23 22:02:13.605 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4857, current loss 3.5248.Counter 3/10.
2024-06-23 22:03:22.385 | INFO     | mltrainer.trainer:report:191 - Epoch 15 train 3.5155 test 3.5039 metric ['3.5039']
2024-06-23 22:03:22.386 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4857, current loss 3.5039.Counter 4/10.
2024-06-23 22:04:28.786 | INFO     | mltrainer.trainer:report:191 - Epoch 16 train 3.5129 test 3.4774 metric ['3.4774']
2024-06-23 22:05:37.813 | INFO     | mltrainer.trainer:report:191 - Epoch 17 train 3.5185 test 3.4851 metric ['3.4851']
2024-06-23 22:05:37.814 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4774, current loss 3.4851.Counter 1/10.
2024-06-23 22:06:44.355 | INFO     | mltrainer.trainer:report:191 - Epoch 18 train 3.5035 test 3.4795 metric ['3.4795']
2024-06-23 22:06:44.356 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4774, current loss 3.4795.Counter 2/10.
2024-06-23 22:07:55.990 | INFO     | mltrainer.trainer:report:191 - Epoch 19 train 3.5173 test 3.4985 metric ['3.4985']
2024-06-23 22:07:55.990 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4774, current loss 3.4985.Counter 3/10.
2024-06-23 22:09:04.229 | INFO     | mltrainer.trainer:report:191 - Epoch 20 train 3.5077 test 3.5123 metric ['3.5123']
2024-06-23 22:09:04.229 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4774, current loss 3.5123.Counter 4/10.
2024-06-23 22:10:14.259 | INFO     | mltrainer.trainer:report:191 - Epoch 21 train 3.5020 test 3.5061 metric ['3.5061']
2024-06-23 22:10:14.260 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4774, current loss 3.5061.Counter 5/10.
2024-06-23 22:11:20.017 | INFO     | mltrainer.trainer:report:191 - Epoch 22 train 3.5089 test 3.4756 metric ['3.4756']
2024-06-23 22:12:29.936 | INFO     | mltrainer.trainer:report:191 - Epoch 23 train 3.5006 test 3.4896 metric ['3.4896']
2024-06-23 22:12:29.937 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4756, current loss 3.4896.Counter 1/10.
2024-06-23 22:13:38.710 | INFO     | mltrainer.trainer:report:191 - Epoch 24 train 3.5157 test 3.4854 metric ['3.4854']
2024-06-23 22:13:38.710 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4756, current loss 3.4854.Counter 2/10.
2024-06-23 22:14:47.336 | INFO     | mltrainer.trainer:report:191 - Epoch 25 train 3.5133 test 3.4888 metric ['3.4888']
2024-06-23 22:14:47.337 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4756, current loss 3.4888.Counter 3/10.
2024-06-23 22:16:01.672 | INFO     | mltrainer.trainer:report:191 - Epoch 26 train 3.4995 test 3.4935 metric ['3.4935']
2024-06-23 22:16:01.673 | INFO     | mltrainer.trainer:__call__:234 - best loss: 3.4756, current loss 3.4935.Counter 4/10.
2024-06-23 22:50:30.095 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 22:50:30.340 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 22:50:30.455 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 16])
2024-06-23 22:50:30.458 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-23 22:50:30.473 | INFO     | __main__:main:63 - Untrained loss: 13.320812225341797
2024-06-23 22:50:30.474 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 22:50:30.483 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-225030
2024-06-23 22:50:31.455 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:02:23.566 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:02:52.870 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:02:53.164 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:02:53.733 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 64])
2024-06-23 23:02:54.130 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-23 23:02:54.132 | INFO     | __main__:main:63 - Untrained loss: 8.711162567138672
2024-06-23 23:02:54.132 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:02:54.141 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-230254
2024-06-23 23:02:55.155 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:28:48.777 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:28:48.990 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:28:49.110 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 32])
2024-06-23 23:28:49.141 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 192])
2024-06-23 23:28:49.146 | INFO     | __main__:main:63 - Untrained loss: 11.408123016357422
2024-06-23 23:28:49.147 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:28:49.155 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-232849
2024-06-23 23:28:50.017 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:29:26.105 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:29:26.298 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:29:26.416 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 32])
2024-06-23 23:29:26.443 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 192])
2024-06-23 23:29:26.448 | INFO     | __main__:main:63 - Untrained loss: 11.41195011138916
2024-06-23 23:29:26.449 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:29:26.458 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-232926
2024-06-23 23:29:27.331 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:30:01.760 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:30:02.050 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:30:02.219 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:30:02.224 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-23 23:30:02.229 | INFO     | __main__:main:63 - Untrained loss: 11.518536567687988
2024-06-23 23:30:02.230 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:30:02.238 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-233002
2024-06-23 23:30:03.112 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:31:49.258 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:31:49.470 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:31:49.545 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:31:49.553 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 32, 192])
2024-06-23 23:32:10.183 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:32:10.403 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:32:10.520 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:32:10.531 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 32, 192])
2024-06-23 23:32:40.014 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:32:40.211 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:32:40.332 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:32:40.341 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 32, 192])
2024-06-23 23:34:24.588 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:34:24.812 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:34:24.934 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:36:07.885 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:36:08.088 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:36:08.211 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:36:08.215 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-23 23:36:08.219 | INFO     | __main__:main:63 - Untrained loss: 10.458491325378418
2024-06-23 23:36:08.219 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:36:08.227 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-233608
2024-06-23 23:36:09.096 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:41:21.644 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:41:21.908 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:41:22.032 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:41:22.036 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-23 23:41:22.038 | INFO     | __main__:main:63 - Untrained loss: 17.6638126373291
2024-06-23 23:41:22.038 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-23 23:41:22.047 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240623-234122
2024-06-23 23:41:22.970 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-23 23:48:11.085 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:48:11.312 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:48:11.434 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 32])
2024-06-23 23:51:36.578 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:51:36.803 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:52:49.094 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:52:49.333 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:53:35.064 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:53:35.259 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:54:14.782 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:54:14.976 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:54:15.106 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:54:53.881 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:54:54.169 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:54:54.310 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:55:56.089 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:55:56.326 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:55:56.469 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:56:55.369 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:57:28.380 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:57:28.614 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:57:28.709 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:58:11.586 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:58:11.794 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:58:11.927 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:59:20.110 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:59:20.327 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:59:20.446 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-23 23:59:37.790 | INFO     | __main__:main:24 - starting exam.py
2024-06-23 23:59:37.982 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-23 23:59:38.075 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:00:31.746 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:00:31.991 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:00:32.137 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:01:12.862 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:01:13.100 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:01:13.239 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:01:44.352 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:01:44.550 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:01:44.646 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:02:35.770 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:02:36.010 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:02:36.147 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:03:22.396 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:03:22.608 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:03:22.703 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:04:08.709 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:04:08.913 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:04:09.014 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:04:09.019 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:04:09.020 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:04:09.020 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:04:53.671 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:04:53.907 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:04:54.043 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:04:54.049 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:04:54.050 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:04:54.051 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:05:26.751 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:05:26.983 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:05:27.135 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:05:27.140 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:05:27.141 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:05:27.142 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:06:06.391 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:06:06.639 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:06:06.792 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:06:06.799 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:06:06.801 | INFO     | __main__:main:63 - Untrained loss: 18.72231674194336
2024-06-24 00:06:06.802 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:06:06.810 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-000606
2024-06-24 00:06:07.774 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:06:42.518 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:06:42.777 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:06:42.912 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:06:42.917 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:06:42.918 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:06:42.918 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:06:42.926 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-000642
2024-06-24 00:06:43.839 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:07:28.004 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:07:28.255 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:07:28.358 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:07:28.363 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:07:28.364 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:07:28.365 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:07:28.372 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-000728
2024-06-24 00:07:29.161 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:09:18.791 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:09:18.996 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:09:19.096 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:09:19.102 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-24 00:09:19.109 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:09:19.109 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:09:19.115 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-000919
2024-06-24 00:09:19.886 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:09:57.772 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:09:57.970 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:09:58.118 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:09:58.123 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:09:58.124 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:09:58.125 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:09:58.132 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-000958
2024-06-24 00:09:58.884 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:10:21.444 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:10:21.677 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:10:21.820 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:10:21.825 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-24 00:10:21.837 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:10:21.838 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:10:21.846 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001021
2024-06-24 00:10:22.713 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:10:43.382 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:10:43.604 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:10:43.701 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:10:43.707 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-24 00:10:43.714 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:10:43.715 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:10:43.720 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001043
2024-06-24 00:10:44.341 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:11:09.773 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:11:10.014 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:11:10.164 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:11:10.169 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 00:11:10.170 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:11:10.171 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:11:10.179 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001110
2024-06-24 00:11:11.009 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:12:05.705 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:12:05.916 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:12:06.067 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:12:06.072 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:12:06.073 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:12:06.074 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:12:06.081 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001206
2024-06-24 00:12:06.883 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:13:23.617 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:13:23.850 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:13:24.005 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:15:01.385 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:15:01.566 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:15:01.653 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:15:36.345 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:15:36.518 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:15:36.616 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:16:22.821 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:16:23.011 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:16:23.109 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:16:23.115 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 192])
2024-06-24 00:16:23.120 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:16:23.120 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:16:23.128 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001623
2024-06-24 00:16:23.732 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:16:55.912 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:16:56.088 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:16:56.183 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:16:56.187 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:16:56.188 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:16:56.189 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:16:56.196 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001656
2024-06-24 00:16:56.790 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:17:21.611 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:17:21.860 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:17:21.957 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:17:21.961 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:17:21.962 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:17:21.962 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:17:21.970 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001721
2024-06-24 00:17:22.582 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:17:36.527 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:17:36.730 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:17:36.871 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:18:15.031 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:18:15.208 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:18:15.303 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:18:46.744 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:18:46.938 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:18:47.026 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:19:06.854 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:19:07.050 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:19:07.140 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:19:23.578 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:19:23.758 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:19:23.852 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:19:23.858 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 128])
2024-06-24 00:19:23.863 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:19:23.863 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:19:23.870 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-001923
2024-06-24 00:19:24.469 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:20:03.681 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:20:03.867 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:20:03.959 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:20:03.965 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 128])
2024-06-24 00:20:03.970 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:20:03.970 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:20:03.977 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002003
2024-06-24 00:20:04.572 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:21:28.469 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:21:28.652 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:21:28.756 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:21:28.760 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 64])
2024-06-24 00:21:28.763 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:21:28.763 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:21:28.770 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002128
2024-06-24 00:21:29.376 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:22:03.759 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:22:03.942 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:22:04.038 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:22:04.046 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 64])
2024-06-24 00:22:04.049 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:22:04.049 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:22:04.057 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002204
2024-06-24 00:22:04.673 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:22:22.622 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:22:22.811 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:22:22.903 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:22:22.910 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 64])
2024-06-24 00:22:22.912 | INFO     | __main__:main:63 - Untrained loss: 8.954965591430664
2024-06-24 00:22:22.913 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:22:22.920 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002222
2024-06-24 00:22:23.515 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:22:46.170 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:22:46.356 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:22:46.451 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:23:11.819 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:23:12.001 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:23:12.102 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:23:12.106 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:23:12.106 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:23:12.107 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:23:12.114 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002312
2024-06-24 00:23:12.715 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:23:34.762 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:23:34.941 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:23:35.033 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:23:35.039 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 1, 1])
2024-06-24 00:23:35.040 | INFO     | __main__:main:63 - Untrained loss: nan
2024-06-24 00:23:35.041 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 00:23:35.048 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-002335
2024-06-24 00:23:35.637 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 00:24:32.383 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:24:32.566 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:24:32.658 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 00:25:43.944 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 00:25:44.111 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 00:25:44.203 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 06:56:02.373 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 06:56:02.576 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 06:56:02.665 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 06:57:06.707 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 06:57:06.883 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 06:57:06.980 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 06:57:40.487 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 06:57:40.674 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 06:57:40.769 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:01:27.515 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:01:46.105 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:01:46.302 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 07:01:46.413 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:01:53.596 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:01:53.771 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 07:01:53.870 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:03:22.218 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:03:22.416 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 07:03:22.545 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:03:22.599 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 07:03:22.600 | INFO     | __main__:main:63 - Untrained loss: 11.691638946533203
2024-06-24 07:03:22.600 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 07:03:22.610 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-070322
2024-06-24 07:03:23.207 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 07:47:41.545 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:47:41.715 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 07:47:41.806 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:47:41.864 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 07:48:03.455 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 07:48:03.640 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 07:48:03.732 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 07:48:03.787 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 07:48:03.789 | INFO     | __main__:main:63 - Untrained loss: 8.676493644714355
2024-06-24 07:48:03.789 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 07:48:03.795 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-074803
2024-06-24 07:48:04.461 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:04:57.524 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:05:28.564 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:05:28.747 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:06:47.181 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:06:47.370 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:06:47.524 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 36864, 64])
2024-06-24 10:06:47.713 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 36864])
2024-06-24 10:07:25.681 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:07:25.855 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:07:25.950 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:07:26.014 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:07:26.016 | INFO     | __main__:main:63 - Untrained loss: 10.514859199523926
2024-06-24 10:07:26.016 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:07:26.022 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-100726
2024-06-24 10:07:26.606 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:12:35.259 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:12:35.434 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:12:35.527 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:12:35.589 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:12:35.591 | INFO     | __main__:main:63 - Untrained loss: 14.765449523925781
2024-06-24 10:12:35.591 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:12:35.596 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-101235
2024-06-24 10:12:36.244 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:13:18.591 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:13:18.760 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:13:18.850 | INFO     | __main__:main:56 - the latent shape : torch.Size([1, 32, 64])
2024-06-24 10:13:18.989 | INFO     | __main__:main:59 - the shape after: torch.Size([1, 6144, 1])
2024-06-24 10:13:36.518 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:13:36.683 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:13:36.773 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:13:36.826 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:13:36.827 | INFO     | __main__:main:63 - Untrained loss: 7.235543727874756
2024-06-24 10:13:36.827 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:13:36.833 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-101336
2024-06-24 10:13:37.430 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:23:49.794 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:23:49.960 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:23:50.049 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:23:50.104 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:23:50.105 | INFO     | __main__:main:63 - Untrained loss: 40.524749755859375
2024-06-24 10:23:50.106 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:23:50.112 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-102350
2024-06-24 10:23:50.751 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:38:09.264 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:38:09.445 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:39:28.574 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:39:28.730 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:39:43.405 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:39:43.561 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:43:04.732 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:43:04.885 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:43:04.969 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:44:37.201 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:44:37.364 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:44:37.454 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:44:37.511 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:44:37.512 | INFO     | __main__:main:63 - Untrained loss: 13.250532150268555
2024-06-24 10:44:37.512 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:44:37.518 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-104437
2024-06-24 10:44:38.104 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:52:20.341 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:52:20.520 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:52:20.609 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:52:20.694 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:52:20.695 | INFO     | __main__:main:63 - Untrained loss: 17.349468231201172
2024-06-24 10:52:20.695 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:52:20.703 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-105220
2024-06-24 10:52:21.278 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:53:15.015 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 10:53:15.184 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 10:53:15.270 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 10:53:15.317 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 10:53:15.318 | INFO     | __main__:main:63 - Untrained loss: 5.877721786499023
2024-06-24 10:53:15.318 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 10:53:15.325 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-105315
2024-06-24 10:53:15.942 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 10:54:59.639 | INFO     | mltrainer.trainer:report:191 - Epoch 0 train 6.1576 test 5.4098 metric ['5.4098']
2024-06-24 10:55:46.591 | INFO     | mltrainer.trainer:report:191 - Epoch 1 train 5.2715 test 5.2565 metric ['5.2565']
2024-06-24 11:03:54.888 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:03:55.087 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:03:55.182 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:03:55.248 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:03:55.249 | INFO     | __main__:main:63 - Untrained loss: 8.440406799316406
2024-06-24 11:03:55.250 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:03:55.256 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-110355
2024-06-24 11:03:56.095 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 11:04:56.990 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:04:57.234 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:04:57.328 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:05:15.971 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:05:16.166 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:05:16.259 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:05:16.325 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:05:16.327 | INFO     | __main__:main:63 - Untrained loss: 8.02917194366455
2024-06-24 11:05:16.327 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:05:16.334 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-110516
2024-06-24 11:05:16.936 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 11:28:49.503 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:28:49.660 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:28:49.743 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:41:02.928 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:41:03.110 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:41:03.201 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:41:03.257 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:41:03.258 | INFO     | __main__:main:63 - Untrained loss: 15.382417678833008
2024-06-24 11:41:03.258 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:41:03.264 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-114103
2024-06-24 11:41:03.852 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 11:44:44.597 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:44:44.769 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:44:44.860 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:44:44.913 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:44:44.914 | INFO     | __main__:main:63 - Untrained loss: 14.241527557373047
2024-06-24 11:44:44.914 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:44:44.920 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-114444
2024-06-24 11:44:45.655 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 11:51:44.226 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:51:44.388 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:51:44.467 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:52:01.165 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:52:01.319 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:52:01.402 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:52:01.447 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:52:01.448 | INFO     | __main__:main:63 - Untrained loss: 11.048194885253906
2024-06-24 11:52:01.449 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:52:01.454 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-115201
2024-06-24 11:52:02.060 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 11:57:17.350 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 11:57:17.499 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 11:57:17.582 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 11:57:17.625 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 11:57:17.626 | INFO     | __main__:main:63 - Untrained loss: 13.477725982666016
2024-06-24 11:57:17.626 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 11:57:17.632 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-115717
2024-06-24 11:57:18.219 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 12:35:21.590 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 12:35:21.744 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 12:35:21.832 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 12:35:21.891 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 12:35:21.892 | INFO     | __main__:main:63 - Untrained loss: 10.297735214233398
2024-06-24 12:35:21.893 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 12:35:21.893 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-123521
2024-06-24 12:36:53.868 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 12:36:54.018 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 12:36:54.100 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 12:36:54.142 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 12:36:54.143 | INFO     | __main__:main:63 - Untrained loss: 10.752327919006348
2024-06-24 12:36:54.143 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 12:36:54.149 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-123654
2024-06-24 12:36:54.725 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 13:02:34.646 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 13:02:34.806 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 13:02:34.886 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 1, 64])
2024-06-24 13:02:34.927 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 13:02:34.928 | INFO     | __main__:main:63 - Untrained loss: 10.967028617858887
2024-06-24 13:02:34.928 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 13:02:34.934 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-130234
2024-06-24 13:02:35.502 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
2024-06-24 14:19:17.691 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 14:19:18.024 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 14:19:18.622 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 512])
2024-06-24 14:19:46.395 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 14:19:46.652 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 14:19:46.727 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 64])
2024-06-24 14:20:00.929 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 14:20:01.080 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 14:20:01.159 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 64])
2024-06-24 14:20:08.156 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 36864, 1])
2024-06-24 14:21:54.347 | INFO     | __main__:main:24 - starting exam.py
2024-06-24 14:21:54.505 | INFO     | __main__:main:53 - the shape before : torch.Size([32, 192, 1])
2024-06-24 14:21:54.586 | INFO     | __main__:main:56 - the latent shape : torch.Size([32, 192, 64])
2024-06-24 14:21:54.628 | INFO     | __main__:main:59 - the shape after: torch.Size([32, 192, 1])
2024-06-24 14:21:54.629 | INFO     | __main__:main:63 - Untrained loss: 12.334824562072754
2024-06-24 14:21:54.629 | INFO     | __main__:main:65 - starting training for 100 epochs
2024-06-24 14:21:54.635 | INFO     | mltrainer.trainer:dir_add_timestamp:29 - Logging to logs/20240624-142154
2024-06-24 14:21:55.234 | INFO     | mltrainer.trainer:__init__:72 - Found earlystop_kwargs in settings.Set to None if you dont want earlystopping.
