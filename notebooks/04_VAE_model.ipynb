{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder\n",
    "\n",
    "The variational autoencoder should be able to identify abnormal heartbeat patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "import gin\n",
    "from streamer import VAEstreamer\n",
    "import vae\n",
    "from loguru import logger\n",
    "\n",
    "import sys\n",
    "import datasets, metrics\n",
    "import mltrainer\n",
    "from mltrainer import ReportTypes, Trainer, TrainerSettings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# use the binary data for training the Variational Autoencoder\n",
    "trainfileVAE = Path('../data/heart_train.parq').resolve()\n",
    "testfileVAE = Path('../data/heart_test.parq').resolve()\n",
    "\n",
    "# Remove outliers for training the VAE\n",
    "traindatasetVAE = datasets.HeartDataset1D(trainfileVAE, target=\"target\", outliersRemoval=True)\n",
    "testdatasetVAE = datasets.HeartDataset1D(testfileVAE, target=\"target\", outliersRemoval=True)\n",
    "\n",
    "validationSetVAE = datasets.HeartDataset1D(testfileVAE, target=\"target\", outliersRemoval=False)\n",
    "\n",
    "trainstreamerVAE = VAEstreamer(traindatasetVAE, batchsize=32).stream()\n",
    "teststreamerVAE = VAEstreamer(testdatasetVAE, batchsize=32).stream()\n",
    "validationstreamerVAE = VAEstreamer(validationSetVAE, batchsize=32).stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-20 11:37:28.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mthe latent shape : torch.Size([32, 2])\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:28.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mthe shape after: torch.Size([32, 192])\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:28.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mUntrained loss: 11.769255638122559\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:28.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mstarting training for 100 epochs\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:28.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /home/azureuser/code/nickyvanoorschot_mads_exam_24/notebooks/logs\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:28.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to logs/20240620-113728\u001b[0m\n",
      "\u001b[32m2024-06-20 11:37:29.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 165.08it/s]\n",
      "\u001b[32m2024-06-20 11:37:30.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 3.4280 test 2.3985 metric ['2.3985']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 179.14it/s]\n",
      "\u001b[32m2024-06-20 11:37:32.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.2208 test 1.9587 metric ['1.9587']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 120.86it/s]\n",
      "\u001b[32m2024-06-20 11:37:34.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 1.8466 test 1.8041 metric ['1.8041']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 184.47it/s]\n",
      "\u001b[32m2024-06-20 11:37:35.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 1.7584 test 1.7253 metric ['1.7253']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 177.19it/s]\n",
      "\u001b[32m2024-06-20 11:37:37.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 1.7003 test 1.6824 metric ['1.6824']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 187.01it/s]\n",
      "\u001b[32m2024-06-20 11:37:38.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 1.6558 test 1.6528 metric ['1.6528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 150.43it/s]\n",
      "\u001b[32m2024-06-20 11:37:40.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 1.6278 test 1.6276 metric ['1.6276']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 139.43it/s]\n",
      "\u001b[32m2024-06-20 11:37:42.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 1.6022 test 1.6021 metric ['1.6021']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:01<00:00, 111.30it/s]\n",
      "\u001b[32m2024-06-20 11:37:44.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 1.5754 test 1.5729 metric ['1.5729']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 98.55it/s] \n",
      "\u001b[32m2024-06-20 11:37:46.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 1.5393 test 1.5721 metric ['1.5721']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 99.11it/s]\n",
      "\u001b[32m2024-06-20 11:37:49.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 1.5208 test 1.5462 metric ['1.5462']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 94.63it/s]\n",
      "\u001b[32m2024-06-20 11:37:51.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 1.4967 test 1.5415 metric ['1.5415']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 93.71it/s]\n",
      "\u001b[32m2024-06-20 11:37:54.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 1.4804 test 1.5196 metric ['1.5196']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 96.71it/s]\n",
      "\u001b[32m2024-06-20 11:37:56.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 1.4674 test 1.4906 metric ['1.4906']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 97.40it/s]\n",
      "\u001b[32m2024-06-20 11:37:59.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 1.4384 test 1.4715 metric ['1.4715']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 91.03it/s]\n",
      "\u001b[32m2024-06-20 11:38:01.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 1.4162 test 1.4528 metric ['1.4528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 94.10it/s]\n",
      "\u001b[32m2024-06-20 11:38:04.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 1.3953 test 1.4382 metric ['1.4382']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 97.07it/s]\n",
      "\u001b[32m2024-06-20 11:38:06.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 1.3722 test 1.4055 metric ['1.4055']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 95.53it/s] \n",
      "\u001b[32m2024-06-20 11:38:09.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 1.3498 test 1.4143 metric ['1.4143']\u001b[0m\n",
      "\u001b[32m2024-06-20 11:38:09.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 1.4055, current loss 1.4143.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 99.96it/s] \n",
      "\u001b[32m2024-06-20 11:38:11.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 1.3198 test 1.3615 metric ['1.3614']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 99.87it/s]\n",
      "\u001b[32m2024-06-20 11:38:14.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 1.3027 test 1.3494 metric ['1.3494']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 94.16it/s]\n",
      "\u001b[32m2024-06-20 11:38:16.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 1.2718 test 1.3282 metric ['1.3282']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 92.41it/s]\n",
      "\u001b[32m2024-06-20 11:38:19.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 1.2570 test 1.3280 metric ['1.3280']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 97.11it/s]\n",
      "\u001b[32m2024-06-20 11:38:22.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 1.2300 test 1.2979 metric ['1.2979']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 94.61it/s]\n",
      "\u001b[32m2024-06-20 11:38:24.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 1.2301 test 1.2747 metric ['1.2747']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 90.27it/s]\n",
      "\u001b[32m2024-06-20 11:38:27.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 1.1972 test 1.2869 metric ['1.2869']\u001b[0m\n",
      "\u001b[32m2024-06-20 11:38:27.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 1.2747, current loss 1.2869.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 86.63it/s]\n",
      "\u001b[32m2024-06-20 11:38:30.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 1.1979 test 1.2528 metric ['1.2528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 88.63it/s]\n",
      "\u001b[32m2024-06-20 11:38:32.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 1.1757 test 1.2829 metric ['1.2829']\u001b[0m\n",
      "\u001b[32m2024-06-20 11:38:32.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 1.2528, current loss 1.2829.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 96.23it/s]\n",
      "\u001b[32m2024-06-20 11:38:35.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 1.1599 test 1.2390 metric ['1.2390']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 93.16it/s]\n",
      "\u001b[32m2024-06-20 11:38:38.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 1.1495 test 1.2371 metric ['1.2371']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 82.25it/s]\n",
      "\u001b[32m2024-06-20 11:38:41.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 1.1425 test 1.2077 metric ['1.2077']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 200/200 [00:02<00:00, 82.00it/s]\n",
      "\u001b[32m2024-06-20 11:38:44.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 1.1186 test 1.2285 metric ['1.2285']\u001b[0m\n",
      "\u001b[32m2024-06-20 11:38:44.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 1.2077, current loss 1.2285.Counter 1/10.\u001b[0m\n",
      " 32%|\u001b[38;2;30;71;6m███▏      \u001b[0m| 32/100 [01:15<03:19,  2.93s/it]"
     ]
    }
   ],
   "source": [
    "gin.parse_config_file(Path('../src/config.gin').resolve())\n",
    "\n",
    "X1, X2 = next(trainstreamerVAE)\n",
    "\n",
    "encoder = vae.Encoder()\n",
    "decoder = vae.Decoder()\n",
    "\n",
    "latent = encoder(X1)\n",
    "logger.info(f\"the latent shape : {latent.shape}\")\n",
    "\n",
    "x = decoder(latent)\n",
    "logger.info(f\"the shape after: {x.shape}\")\n",
    "\n",
    "lossfn = vae.ReconstructionLoss()\n",
    "loss = lossfn(x, X2)\n",
    "logger.info(f\"Untrained loss: {loss}\")\n",
    "\n",
    "logger.info(f\"starting training for {100} epochs\")\n",
    "autoencoder = vae.AutoEncoder()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=100,\n",
    "    metrics=[lossfn],\n",
    "    logdir=\"logs\",\n",
    "    train_steps=200,\n",
    "    valid_steps=200,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 10},\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=autoencoder,\n",
    "    settings=settings,\n",
    "    loss_fn=lossfn,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    traindataloader=trainstreamerVAE,\n",
    "    validdataloader=teststreamerVAE,\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "testdata = validationstreamerVAE.stream()\n",
    "for _ in range(len(validationstreamerVAE)):\n",
    "    X, y = next(testdata)\n",
    "    yhat = autoencoder(X)\n",
    "    yhat = yhat.argmax(dim=1) # we get the one with the highest probability\n",
    "    y_pred.append(yhat.cpu().tolist())\n",
    "    y_true.append(y.cpu().tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "# cfm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "\n",
    "plot = sns.heatmap(cfm, annot=cfm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
